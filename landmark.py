from __future__ import print_function, division
import torch
import torch.optim as optim
from torchvision import transforms
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
import os
from MyDataLoader import ToTensor, LandmarksDataset
import MyModel
import TrainNet
import LossFunction
import argparse
import warnings
warnings.filterwarnings("ignore", category=UserWarning) # å¿½ç•¥æ‰€æœ‰ UserWarning ç±»å‹çš„è­¦å‘Š
plt.ion()  # interactive mode

parser = argparse.ArgumentParser()
# æ¨¡å‹è®­ç»ƒéƒ¨åˆ†çš„å‚æ•°
parser.add_argument("--batchSize", type=int, default=1)
parser.add_argument("--landmarkNum", type=int, default=7)
parser.add_argument("--image_scale", default=(96, 96, 96), type=tuple)  # é™é‡‡æ ·å›¾åƒå°ºå¯¸
parser.add_argument("--origin_image_size", default=(512, 512, 512), type=tuple) # åŸå§‹å›¾åƒå°ºå¯¸
parser.add_argument("--crop_size", default=(64, 64, 64), type=tuple)        # è£å‰ªå—å°ºå¯¸, 32ä¿®æ”¹ä¸º64
parser.add_argument("--use_gpu", type=int, default=0)
parser.add_argument("--iteration", type=int, default=3)                 # LSTMçš„é•¿åº¦
# parser.add_argument("--R1", type=int, default=5)              # æš‚æ—¶æ²¡æœ‰ä½¿ç”¨åˆ°è¿™ä¸¤ä¸ªå‚æ•°
# parser.add_argument("--R2", type=int, default=9)
parser.add_argument("--epochs", type=int, default=50)          # è¿­ä»£æ¬¡æ•°
parser.add_argument("--data_enhanceNum", type=int, default=5)   # TODO:æ•°æ®å¢å¼º
parser.add_argument('--lr', type=float, default=0.0001)     # å­¦ä¹ ç‡
parser.add_argument("--spacing", type=tuple, default=(0.5, 0.5, 0.5))   # npyæ•°æ®çš„ä½“ç´ é—´è·
parser.add_argument("--stage", type=str, default="train")       # é»˜è®¤ä¸ºè®­ç»ƒæ¨¡å¼
parser.add_argument("--resume", type=str, default=None, help="Path to checkpoint to resume from (e.g., 'runs/exp1')") # ä»å“ªä¸ªè·¯å¾„ä¸‹çš„æƒé‡å¼€å§‹ç»§ç»­è®­ç»ƒ
# è¾“å…¥æ•°æ®éƒ¨åˆ†å‚æ•°
parser.add_argument('--dataRoot', type=str, default="./processed_data/")   # npyæ ¼å¼æ•°æ®è·¯å¾„  ä½¿ç”¨æ ¹ç›®å½•ï¼Œè¿™æ ·æœåŠ¡å™¨ä¸Šé¢å¯ä»¥ç›´æ¥è¿è¡Œ
parser.add_argument("--traincsv", type=str, default='train.csv')    # è®­ç»ƒæ•°æ®
parser.add_argument("--testcsv", type=str, default='test.csv')      # æµ‹è¯•æ•°æ®
# è¾“å‡ºä¿å­˜éƒ¨åˆ†å‚æ•° 
parser.add_argument("--saveName", type=str, default='Data_enhance_test')         # ä¿®æ”¹é…ç½®ä»¥åè¦ä¿®æ”¹saveNameæ¥ä¿å­˜è®­ç»ƒæ•°æ®
# åŠ è½½å“ªä¸ªæ–‡ä»¶å¤¹çš„æƒé‡è¿›è¡Œæµ‹è¯•
parser.add_argument("--testName", type=str, default="test3")    # é€‰æ‹©å“ªä¸ªé…ç½®æ¥æµ‹è¯•æ•°æ®


def main():
    config = parser.parse_args()
    fine_LSTM = MyModel.fine_LSTM(config).cuda(config.use_gpu)
    coarseNet = MyModel.coarseNet(config).cuda(config.use_gpu)

    # å®šä¹‰æ•°æ®é¢„å¤„ç†æµæ°´çº¿(Pipeline)è½¬æ¢ä¸ºTensoræ ¼å¼
    transform_origin = transforms.Compose([
        # Rescale(config.origin_image_size),    # å›¾åƒåœ¨é¢„å¤„ç†çš„æ—¶å€™å·²ç»Resizeäº†
        ToTensor()
    ])

    # æµ‹è¯•æ¨¡å¼
    if config.stage == 'test':
        print(f"ğŸš€ Mode: TEST | Loading weights from: {config.testName}")
        
        # åŠ è½½æƒé‡
        save_dir = os.path.join('runs', config.testName)
        coarseNet.load_state_dict(torch.load(os.path.join(save_dir, 'best_coarse.pth')))
        fine_LSTM.load_state_dict(torch.load(os.path.join(save_dir, 'best_fine_LSTM.pth')))
            
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_dataset = LandmarksDataset(
            csv_file=config.dataRoot + config.testcsv,
            root_dir=config.dataRoot + "images",
            transform=transform_origin,
            landmarksNum=config.landmarkNum,
        )
        test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)
        
        # 3. æ‰§è¡Œæµ‹è¯•
        TrainNet.test_model(coarseNet, fine_LSTM, test_dataloader, config)
        return # æµ‹è¯•ç»“æŸåç›´æ¥é€€å‡º

    train_dataset_origin = LandmarksDataset(csv_file=config.dataRoot + config.traincsv,
                                            root_dir=config.dataRoot + "images",
                                            transform=transform_origin,
                                            landmarksNum=config.landmarkNum
                                            )

    val_dataset = LandmarksDataset(csv_file=config.dataRoot + config.testcsv,
                                   root_dir=config.dataRoot + "images",
                                   transform=transform_origin,
                                   landmarksNum=config.landmarkNum
                                   )
    
    # train_dataloader = []
    # val_dataloader = []

    # # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼Œå¯é«˜æ•ˆè¯»å–çš„æ‰¹é‡æ•°æ®
    # train_dataloader_t = DataLoader(train_dataset_origin, batch_size=config.batchSize, shuffle=False, num_workers=0)
    # for data in train_dataloader_t:
    #     train_dataloader.append(data)

    # val_dataloader_t = DataLoader(val_dataset, batch_size=config.batchSize, shuffle=False, num_workers=0)
    # for data in val_dataloader_t:
    #     val_dataloader.append(data)

    # ç›´æ¥ä½¿ç”¨ DataLoaderï¼Œä¸è¦ç”¨ List Appendï¼
    # è¿™æ ·ç¨‹åºä¼šç¬é—´å¯åŠ¨ï¼Œè®­ç»ƒæ—¶åå°åŠ è½½
    train_dataloader = DataLoader(
        train_dataset_origin, 
        batch_size=config.batchSize, 
        shuffle=True,       # å¿…é¡»æ‰“ä¹±
        num_workers=0,      # è®¾ç½®ä¸º CPU æ ¸å¿ƒæ•°
        pin_memory=True,    # åŠ é€Ÿ CPU -> GPU ä¼ è¾“
        # persistent_workers=True
    )
    # éªŒè¯é›†
    val_dataloader = DataLoader(
        val_dataset, 
        batch_size=config.batchSize, 
        shuffle=False, 
        num_workers=0,
        # pin_memory=True
    )

    print(f"train data:{len(train_dataloader)}, test data:{len(val_dataloader)}")

    dataloaders = {'train': train_dataloader, 'val': val_dataloader}

    criterion_coarse = LossFunction.coarse_heatmap(config)
    criterion_fine = LossFunction.fine_heatmap(config)

    params = list(coarseNet.parameters()) + list(fine_LSTM.parameters())

    optimizer_ft = optim.Adam(params, lr=config.lr, weight_decay=1e-4)  # æƒé‡è¡°å‡ï¼Œå¦‚æœä¾ç„¶è¿‡æ‹Ÿåˆï¼Œå°è¯•åŠ é‡åˆ°1e-3

    TrainNet.train_model(coarseNet, fine_LSTM, dataloaders, criterion_coarse, criterion_fine,
                         optimizer_ft, config)

if __name__ == "__main__":
    main()