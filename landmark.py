from __future__ import print_function, division
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable
import numpy as np
import torchvision
from torchvision import models, transforms, utils
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
import time
import os
import math
from copy import deepcopy
import pandas as pd
from MyDataLoader import Rescale, ToTensor, LandmarksDataset
import MyModel
import TrainNet
import LossFunction
import argparse
import warnings
warnings.filterwarnings("ignore", category=UserWarning) # å¿½ç•¥æ‰€æœ‰ UserWarning ç±»å‹çš„è­¦å‘Š

plt.ion()  # interactive mode

parser = argparse.ArgumentParser()
# æ¨¡å‹è®­ç»ƒéƒ¨åˆ†çš„å‚æ•°
parser.add_argument("--batchSize", type=int, default=1)
parser.add_argument("--landmarkNum", type=int, default=7)
parser.add_argument("--image_scale", default=(96, 96, 96), type=tuple)  # é™é‡‡æ ·å›¾åƒå°ºå¯¸
parser.add_argument("--origin_image_size", default=(512, 512, 512), type=tuple) # åŸå§‹å›¾åƒå°ºå¯¸
parser.add_argument("--crop_size", default=(32, 32, 32), type=tuple)        # è£å‰ªå—å°ºå¯¸
parser.add_argument("--use_gpu", type=int, default=0)
parser.add_argument("--iteration", type=int, default=3)                 # LSTMçš„é•¿åº¦
parser.add_argument("--R1", type=int, default=5)
parser.add_argument("--R2", type=int, default=9)
parser.add_argument("--epochs", type=int, default=50)          # è¿­ä»£æ¬¡æ•°
parser.add_argument("--data_enhanceNum", type=int, default=1)   # TODO:æ•°æ®å¢å¼º
parser.add_argument('--lr', type=float, default=0.0001)     # å­¦ä¹ ç‡
parser.add_argument("--spacing", type=tuple, default=(0.5, 0.5, 0.5))   # npyæ•°æ®çš„ä½“ç´ é—´è·
parser.add_argument("--stage", type=str, default="test")       # é»˜è®¤ä¸ºè®­ç»ƒæ¨¡å¼
# è¾“å…¥æ•°æ®éƒ¨åˆ†å‚æ•°
parser.add_argument('--dataRoot', type=str, default="F:/CBCT/SA-LSTM-3D-Landmark-Detection2/processed_data/")   # npyæ ¼å¼æ•°æ®è·¯å¾„
parser.add_argument("--traincsv", type=str, default='train.csv')    # è®­ç»ƒæ•°æ®
parser.add_argument("--testcsv", type=str, default='test.csv')      # æµ‹è¯•æ•°æ®
# è¾“å‡ºä¿å­˜éƒ¨åˆ†å‚æ•°
parser.add_argument("--saveName", type=str, default='test3')         # ä¿®æ”¹é…ç½®ä»¥åè¦ä¿®æ”¹saveNameæ¥ä¿å­˜è®­ç»ƒæ•°æ®
parser.add_argument("--testName", type=str, default="test3")    # é€‰æ‹©å“ªä¸ªé…ç½®æ¥æµ‹è¯•æ•°æ®


def main():
    config = parser.parse_args()
    fine_LSTM = MyModel.fine_LSTM(config).cuda(config.use_gpu)
    coarseNet = MyModel.coarseNet(config).cuda(config.use_gpu)

    # # åœ¨æµ‹è¯•é˜¶æ®µï¼Œä»æŒ‡å®šè·¯å¾„åŠ è½½é¢„è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œå¹¶å°†æ¨¡å‹åŠ è½½åˆ°æŒ‡å®šçš„GPUä¸Šï¼Œmap_locationå‚æ•°ç”¨äºæŒ‡å®šæ¨¡å‹åŠ è½½åˆ°æŒ‡å®šçš„GPUä¸Šï¼Œé»˜è®¤ä¸ºcuda(0)ï¼Œå³ç¬¬0ä¸ªGPU
    # if config.stage == 'test':
    #     fine_LSTM = torch.load('output/' + "730" + config.testName + "fine_LSTM.pkl", map_location=lambda storage, loc:storage.cuda(config.use_gpu))
    #     coarseNet = torch.load('output/' + "730" + config.testName + "coarse.pkl", map_location=lambda storage, loc:storage.cuda(config.use_gpu))

    # å®šä¹‰æ•°æ®é¢„å¤„ç†æµæ°´çº¿(Pipeline)è½¬æ¢ä¸ºTensoræ ¼å¼
    transform_origin = transforms.Compose([
        # Rescale(config.origin_image_size),    # å›¾åƒåœ¨é¢„å¤„ç†çš„æ—¶å€™å·²ç»Resizeäº†
        ToTensor()
    ])

    # æµ‹è¯•æ¨¡å¼
    if config.stage == 'test':
        print(f"ğŸš€ Mode: TEST | Loading weights from: {config.testName}")
        
        # åŠ è½½æƒé‡
        save_dir = os.path.join('runs', config.testName)
        coarseNet.load_state_dict(torch.load(os.path.join(save_dir, 'best_coarse.pth')))
        fine_LSTM.load_state_dict(torch.load(os.path.join(save_dir, 'best_fine_LSTM.pth')))
            
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_dataset = LandmarksDataset(
            csv_file=config.dataRoot + config.testcsv,
            root_dir=config.dataRoot + "images",
            transform=transform_origin,
            landmarksNum=config.landmarkNum,
        )
        test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)
        
        # 3. æ‰§è¡Œæµ‹è¯•
        TrainNet.test_model(coarseNet, fine_LSTM, test_dataloader, config)
        
        return # æµ‹è¯•ç»“æŸåç›´æ¥é€€å‡º

    train_dataset_origin = LandmarksDataset(csv_file=config.dataRoot + config.traincsv,
                                            root_dir=config.dataRoot + "images",
                                            transform=transform_origin,
                                            landmarksNum=config.landmarkNum
                                            )

    val_dataset = LandmarksDataset(csv_file=config.dataRoot + config.testcsv,
                                   root_dir=config.dataRoot + "images",
                                   transform=transform_origin,
                                   landmarksNum=config.landmarkNum
                                   )
    
    train_dataloader = []
    val_dataloader = []

    # åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ï¼Œå¯é«˜æ•ˆè¯»å–çš„æ‰¹é‡æ•°æ®
    train_dataloader_t = DataLoader(train_dataset_origin, batch_size=config.batchSize, shuffle=False, num_workers=0)
    for data in train_dataloader_t:
        train_dataloader.append(data)

    val_dataloader_t = DataLoader(val_dataset, batch_size=config.batchSize, shuffle=False, num_workers=0)
    for data in val_dataloader_t:
        val_dataloader.append(data)

    print(len(train_dataloader), len(val_dataloader))

    dataloaders = {'train': train_dataloader, 'val': val_dataloader}

    criterion_coarse = LossFunction.coarse_heatmap(config)
    criterion_fine = LossFunction.fine_heatmap(config)

    # Observe that all parameters are being optimized
    params = list(coarseNet.parameters()) + list(fine_LSTM.parameters())

    optimizer_ft = optim.Adam(params, lr=config.lr)

    TrainNet.train_model(coarseNet, fine_LSTM, dataloaders, criterion_coarse, criterion_fine,
                         optimizer_ft, config)

if __name__ == "__main__":
    main()