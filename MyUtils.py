from __future__ import print_function, division
import torch
import numpy as np
import matplotlib.pyplot as plt
import math
from copy import deepcopy
import pandas as pd
import math
from PIL import Image, ImageDraw, ImageFont
from scipy.ndimage import zoom
import torch.nn.functional as F
import logging
import sys

def analysis_result(landmarkNum, Off):  # å¯ä»¥å¤„ç†ç¼ºå¤±å€¼ï¼ˆå¸¦NaNçš„æƒ…å†µï¼‰
    # ç¡®ä¿æ•°æ®åœ¨ CPU ä¸Šä»¥å…å ç”¨æ˜¾å­˜ï¼Œä¸”æ–¹ä¾¿è®¡ç®—
    if Off.is_cuda:
        Off = Off.cpu()

    thresholds = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]
    
    # åˆå§‹åŒ–è¾“å‡ºçŸ©é˜µ
    SDR = torch.zeros((landmarkNum, len(thresholds)))
    SD = torch.zeros((landmarkNum))
    
    # 1. è®¡ç®— MRE (Mean Radial Error)
    MRE = torch.nanmean(Off, dim=0) 

    # 2. è®¡ç®— SDR å’Œ SD
    for landmarkId in range(landmarkNum):
        landmarkCol = Off[:, landmarkId]
        
        # åˆ©ç”¨ torch.isnan æå–æœ‰æ•ˆæ•°æ®   ~torch.isnan() è¡¨ç¤ºå–åï¼Œå³â€œéNaNâ€
        valid_mask = ~torch.isnan(landmarkCol)
        valid_data = landmarkCol[valid_mask]
        
        if valid_data.numel() > 0: # å¦‚æœæœ‰æœ‰æ•ˆæ•°æ®
            # è®¡ç®—æ ‡å‡†å·®
            SD[landmarkId] = torch.std(valid_data)
            
            # è®¡ç®—ä¸åŒé˜ˆå€¼ä¸‹çš„æˆåŠŸç‡ SDR
            for i, th in enumerate(thresholds):
                SDR[landmarkId, i] = torch.le(valid_data, th).float().mean() # torch.le æ˜¯ <= (Less Equal)  .float().mean() è‡ªåŠ¨è®¡ç®— True çš„æ¯”ä¾‹
        else:
            SD[landmarkId] = 0.0
            SDR[landmarkId, :] = 0.0

    return SDR, SD, MRE         # è¿”å›çš„MREæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œä»£è¡¨7ä¸ªå…³é”®ç‚¹å„è‡ªçš„å¹³å‡è¯¯å·®


def analysis_result_overall(Off):
    """
    è®¡ç®—æ‰€æœ‰åœ°æ ‡çš„æ•´ä½“ç»Ÿè®¡æŒ‡æ ‡
    Args:
        Off: å½¢çŠ¶ä¸º (N, landmarkNum) çš„è¯¯å·®çŸ©é˜µ
    Returns:
        overall_SDR: æ•´ä½“SDR (8ä¸ªé˜ˆå€¼)
        overall_SD: æ•´ä½“æ ‡å‡†å·®
        overall_MRE: æ•´ä½“å¹³å‡è¯¯å·®
    """
    # å°†æ‰€æœ‰åœ°æ ‡çš„è¯¯å·®å±•å¹³
    all_errors = Off.flatten()
    
    # è®¡ç®—æ•´ä½“MRE
    overall_MRE = np.mean(all_errors)
    
    # è®¡ç®—æ•´ä½“SD
    overall_SD = np.sqrt(np.sum(np.power(all_errors - overall_MRE, 2)) / (len(all_errors) - 1))
    
    # è®¡ç®—æ•´ä½“SDR
    overall_SDR = np.array([
        np.sum(all_errors <= 1) / len(all_errors),
        np.sum(all_errors <= 2) / len(all_errors),
        np.sum(all_errors <= 3) / len(all_errors),
        np.sum(all_errors <= 4) / len(all_errors),
        np.sum(all_errors <= 5) / len(all_errors),
        np.sum(all_errors <= 6) / len(all_errors),
        np.sum(all_errors <= 7) / len(all_errors),
        np.sum(all_errors <= 8) / len(all_errors)
    ])
    
    return overall_SDR, overall_SD, overall_MRE

def adjustment(ROIs, labels):
    temoff = (ROIs - labels)
    temoff[temoff > 0.055] = temoff[temoff > 0.055] * 0 + 0.055
    temoff[temoff < -0.055] = temoff[temoff < -0.055] * 0 - 0.055
    ROIs = labels + temoff
    return ROIs

def Mydist(a, b):
    x1, y1 = a
    x2, y2 = b
    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)

def Mydist3D(a, b):
    z1, x1, y1 = a
    z2, x2, y2 = b
    return math.sqrt((z2 - z1) ** 2 + (x2 - x1) ** 2 + (y2 - y1) ** 2)

def get_coordinates_from_coarse_heatmaps(predicted_heatmap, global_coordinate):
    lent = len(predicted_heatmap)
    index = [2, 1, 0]       # æ­£ç¡®çš„ç´¢å¼•
    global_coordinate_permute = global_coordinate.permute(3, 0, 1, 2)
    predict = [torch.sum((global_coordinate_permute * predicted_heatmap[i]).view(3, -1), dim = 1).unsqueeze(0) for i in range(lent)]
    predict = torch.cat(predict, dim=0)
    return predict[:, index]

def get_coordinates_from_fine_heatmaps(heatMaps, global_coordinate):
    lent = len(heatMaps)
    global_heatmap = [torch.sigmoid(heatMaps[i]) for i in range(lent)]
    global_heatmap = [global_heatmap[i] / global_heatmap[i].sum() for i in range(lent)]
    index = [1, 2, 0]
    global_coordinate_permute = global_coordinate.permute(3, 0, 1, 2)
    predict = [torch.sum((global_coordinate_permute * global_heatmap[i]).view(3, -1), dim = 1).unsqueeze(0) for i in range(lent)]
    predict = torch.cat(predict, dim=0)
    return predict[:, index]

def get_fine_errors(predicted_offset, labels, size_tensor):    # size_tensor å¿…é¡»æ˜¯ç‰©ç†å°ºå¯¸ (mm)
    predict = predicted_offset * size_tensor.unsqueeze(1)
    labels_b = labels * size_tensor.unsqueeze(1)
    diff = predict - labels_b   # è®¡ç®—å·®å€¼(mm)
    tem_dist = torch.norm(diff, p=2, dim=2) # è®¡ç®—æ¬§æ°è·ç¦»
    return tem_dist # (B, N)

def get_coarse_errors(coarse_landmarks, labels, size_tensor):
    predict = coarse_landmarks * size_tensor.unsqueeze(1)
    labels_b = labels * size_tensor.unsqueeze(1)
    diff = predict - labels_b   # è®¡ç®—å·®å€¼(mm)
    tem_dist = torch.norm(diff, p=2, dim=2) # è®¡ç®—æ¬§æ°è·ç¦»
    return tem_dist

def get_global_feature(ROIs, coarse_feature, landmarkNum):
    # åŸå§‹ä»£ç ï¼š
    # X1, Y1, Z1 = ROIs[:, :, 0], ROIs[:, :, 1], ROIs[:, :, 2]
    # L, H, W = coarse_feature.size()[-3:]
    # X1, Y1, Z1 = np.round(X1 * (H - 1)).astype("int"), np.round(Y1 * (W - 1)).astype("int"), np.round(Z1 * (L - 1)).astype("int")
    # global_embedding = torch.cat([coarse_feature[:, :, Z1[0, i], X1[0, i], Y1[0, i]] for i in range(landmarkNum)], dim=0).unsqueeze(0)
    # return global_embedding

    # åŸå§‹ä»£ç é¢„æµ‹ç»“æœå¯èƒ½ä¼šè¶Šç•Œï¼Œè¿™é‡Œè¿›è¡Œä¼˜åŒ–
    # ROIs shape: [1, landmarkNum, 3]  coarse_feature shape: [B, C, L, H, W]
    # 1. åŠ¨æ€è·å– feature map çš„ç»´åº¦ä¿¡æ¯   L: Depth (Z), H: Height (X), W: Width (Y)
    L, H, W = coarse_feature.size()[-3:]
    
    # 2. æå–å½’ä¸€åŒ–åæ ‡å¹¶è¿›è¡Œç»´åº¦å®‰å…¨é™åˆ¶ ä½¿ç”¨ np.clip å°†åæ ‡é™åˆ¶åœ¨ [0, 1] ä¹‹é—´ï¼Œé˜²æ­¢åŸå§‹ ROIs è¶Šç•Œ
    X1_norm = np.clip(ROIs[:, :, 0], 0, 1)
    Y1_norm = np.clip(ROIs[:, :, 1], 0, 1)
    Z1_norm = np.clip(ROIs[:, :, 2], 0, 1)
    
    # 3. è®¡ç®—æ•´æ•°ç´¢å¼•å¹¶å†æ¬¡ç¡®ä¿ä¸è¶Šç•Œ (0 åˆ° size-1)  np.round(val * (size - 1)) èƒ½ç²¾å‡†æ˜ å°„åˆ°æœ€åä¸€ä¸ªåƒç´ ä¸­å¿ƒ
    X1 = np.round(X1_norm * (H - 1)).astype("int")
    Y1 = np.round(Y1_norm * (W - 1)).astype("int")
    Z1 = np.round(Z1_norm * (L - 1)).astype("int")
    
    # 4. æå–ç‰¹å¾ ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼æå–æ¯ä¸ª landmark å¯¹åº”çš„ç‰¹å¾å‘é‡  coarse_feature[:, :, z, x, y] æå–çš„æ˜¯ [B, C] çš„ç‰¹å¾
    global_embedding = torch.cat(
        [coarse_feature[:, :, Z1[0, i], X1[0, i], Y1[0, i]] for i in range(landmarkNum)], 
        dim=0
    ).unsqueeze(0)
    return global_embedding

# def getcropedInputs_related(ROIs, labels, inputs_origin, useGPU, index, config):
#     # # ğŸ”¥ [DEBUG] æ‰“å°æ¡ˆå‘ç°åœºå½¢çŠ¶
#     # if len(inputs_origin) > 0:
#     #     print(f"[DEBUG 3 - CrashSite] inputs_origin[0] shape in MyUtils: {inputs_origin[0].shape}")
    
#     labels_b = labels.detach().cpu().numpy()
#     landmarks = ROIs
#     landmarkNum = len(inputs_origin)

#     b, c, l, h, w = inputs_origin[0].size()

#     L, H, W = config.origin_image_size
#     cropSize = 0
#     if index == 0:
#         cropSize = 32
#     elif index == 1:
#         cropSize = 16
#     else:
#         cropSize = 8

#     # ~ print ("origin ", inputs_origin.size())

#     X1, Y1, Z1 = landmarks[:, :, 0], landmarks[:, :, 1], landmarks[:, :, 2]
#     X1, Y1, Z1 = np.round(X1 * (H - 1)).astype("int"), np.round(Y1 * (W - 1)).astype("int"), np.round(Z1 * (L - 1)).astype("int")

#     X2, Y2, Z2 = labels_b[:, :, 0], labels_b[:, :, 1], labels_b[:, :, 2]
#     X2, Y2, Z2 = np.round(X2 * (H - 1)).astype("int"), np.round(Y2 * (W - 1)).astype("int"), np.round(Z2 * (L - 1)).astype("int")

#     X, Y, Z = X1 - X2 + int(h/2), Y1 - Y2 + int(w/2), Z1 - Z2 + int(l/2)
#     # print(X, Y, Z)


#     cropedDICOMs = []
#     flag = True
#     for landmarkId in range(landmarkNum):
#         z, x, y = Z[0][landmarkId], X[0][landmarkId], Y[0][landmarkId]

#         # if z<0 or z >= l or x < 0 or x >=h or y < 0 or y >= w:
#         #     cropedDICOMs.append(torch.zeros(1, 1, 32, 32, 32))
#         #     continue

#         lz, uz, lx, ux, ly, uy = z - cropSize, z + cropSize, x - cropSize, x + cropSize, y - cropSize, y + cropSize
#         lzz, uzz, lxx, uxx, lyy, uyy = max(lz, 0), min(uz, l), max(lx, 0), min(ux, h), max(ly, 0), min(uy, w)

#         # ~ print (z, x, y)
#         # ~ print ("boxes ", lz, uz, lx, ux, ly, uy)
#         cropedDICOM = inputs_origin[landmarkId][:, :, lzz: uzz, lxx: uxx, lyy: uyy].clone()
#         # ~ print ("check before", cropedDICOM.size())
#         if lz < 0:
#             _, _, curentZ, curentX, curentY = cropedDICOM.size()
#             temTensor = torch.zeros(b, c, 0 - lz, curentX, curentY)
#             if useGPU >= 0: temTensor = temTensor.cuda(useGPU)
#             cropedDICOM = torch.cat((temTensor, cropedDICOM), 2)
#         if uz > l:
#             _, _, curentZ, curentX, curentY = cropedDICOM.size()
#             temTensor = torch.zeros(b, c, uz - l, curentX, curentY)
#             if useGPU >= 0: temTensor = temTensor.cuda(useGPU)
#             cropedDICOM = torch.cat((cropedDICOM, temTensor), 2)
#         if lx < 0:
#             _, _, curentZ, curentX, curentY = cropedDICOM.size()
#             temTensor = torch.zeros(b, c, curentZ, 0 - lx, curentY)
#             if useGPU >= 0: temTensor = temTensor.cuda(useGPU)
#             cropedDICOM = torch.cat((temTensor, cropedDICOM), 3)
#         if ux > h:
#             _, _, curentZ, curentX, curentY = cropedDICOM.size()
#             temTensor = torch.zeros(b, c, curentZ, ux - h, curentY)
#             if useGPU >= 0: temTensor = temTensor.cuda(useGPU)
#             cropedDICOM = torch.cat((cropedDICOM, temTensor), 3)
#         if ly < 0:
#             _, _, curentZ, curentX, curentY = cropedDICOM.size()
#             temTensor = torch.zeros(b, c, curentZ, curentX, 0 - ly)
#             if useGPU >= 0: temTensor = temTensor.cuda(useGPU)
#             cropedDICOM = torch.cat((temTensor, cropedDICOM), 4)
#         if uy > w:
#             _, _, curentZ, curentX, curentY = cropedDICOM.size()
#             temTensor = torch.zeros(b, c, curentZ, curentX, uy - w)
#             if useGPU >= 0: temTensor = temTensor.cuda(useGPU)
#             cropedDICOM = torch.cat((cropedDICOM, temTensor), 4)

#         # cropedDICOMs.append(cropedDICOM)
#         cropedDICOMs.append(F.upsample(cropedDICOM, size=(32, 32, 32), mode='trilinear'))

#     # ~ print (cropedDICOMs.size())
#     return cropedDICOMs


# MyUtils.py ä¸­çš„ getcropedInputs_related å‡½æ•°

def getcropedInputs_related(ROIs, labels, inputs_origin, useGPU, index, config):
    """
    é’ˆå¯¹ Full Image çš„æç®€åˆ‡å›¾å‡½æ•°
    ç›´æ¥æ ¹æ® ROIs åœ¨åŸå›¾ä¸Šåˆ‡å‡º patch
    """
    # 1. å‡†å¤‡å›¾åƒæ•°æ® (Tensor)
    img_tensor = inputs_origin[0]

    # ç»´åº¦å…¼å®¹æ€§å¤„ç†: (C, D, H, W) -> (1, C, D, H, W)
    if img_tensor.dim() == 4:
        img_tensor = img_tensor.unsqueeze(0)

    # ç°åœ¨çš„ img_tensor ä¿è¯æ˜¯ 5 ç»´ (B, C, D, H, W)
    b, c, D, H, W = img_tensor.size()
    
    # 2. ç¡®å®š Crop Size
    base_size = 64 # æ ¹æ® config.crop_size è°ƒæ•´
    if index == 0:   crop_r = base_size // 2      # r=32
    elif index == 1: crop_r = base_size // 4      # r=16
    else:            crop_r = base_size // 8      # r=8

    # 3. è®¡ç®—ä¸­å¿ƒåæ ‡ (åå½’ä¸€åŒ–)
    # ROIs å¯èƒ½ä¼ è¿›æ¥æ˜¯ (Batch, N, 3)ï¼Œè¿™é‡Œå– Batch 0
    current_rois = ROIs[0] # (N, 3)
    landmarkNum = current_rois.shape[0]

    L_o, H_o, W_o = config.origin_image_size
    
    # ğŸ”¥ [ä¿®å¤æ ¸å¿ƒ] å…¼å®¹ Tensor å’Œ Numpy è¾“å…¥
    if isinstance(current_rois, torch.Tensor):
        x_raw = current_rois[:, 0].detach().cpu().numpy()
        y_raw = current_rois[:, 1].detach().cpu().numpy()
        z_raw = current_rois[:, 2].detach().cpu().numpy()
    else:
        x_raw = current_rois[:, 0]
        y_raw = current_rois[:, 1]
        z_raw = current_rois[:, 2]
    
    # è®¡ç®—åƒç´ åæ ‡ (å‡è®¾ ROIs å¯¹åº” W, H, D å³ X, Y, Z)
    # æ³¨æ„ï¼šè¯·ç¡®ä¿ä½ çš„ ROIs åæ ‡å®šä¹‰å’Œå›¾åƒç»´åº¦æ˜¯ä¸€è‡´çš„
    cX = np.round(x_raw * (W_o - 1)).astype(int)
    cY = np.round(y_raw * (H_o - 1)).astype(int)
    cZ = np.round(z_raw * (L_o - 1)).astype(int)

    cropedDICOMs = []
    
    # 4. å¼€å§‹åˆ‡å›¾
    for i in range(landmarkNum):
        # æå–ä¸­å¿ƒç‚¹ (PyTorch Tensor é¡ºåºé€šå¸¸æ˜¯ D, H, W -> z, y, x)
        z, y, x = cZ[i], cY[i], cX[i]
        
        # è®¡ç®—è¾¹ç•Œ
        lz, uz = z - crop_r, z + crop_r
        ly, uy = y - crop_r, y + crop_r
        lx, ux = x - crop_r, x + crop_r
        
        # é’³ä½è¾¹ç•Œ (ç”¨äº Slice)
        lzz, uzz = max(lz, 0), min(uz, D)
        lyy, uyy = max(ly, 0), min(uy, H)
        lxx, uxx = max(lx, 0), min(ux, W)
        
        # åˆ‡ç‰‡ (è¿™é‡Œéœ€è¦ 5 ç»´æ•°æ®)
        patch = img_tensor[:, :, lzz:uzz, lyy:uyy, lxx:uxx].clone()
        
        # Padding (å¦‚æœåˆ‡å‡ºç•Œäº†è¡¥é›¶)
        pad_z_l = abs(lz) if lz < 0 else 0
        pad_z_r = (uz - D) if uz > D else 0
        pad_y_l = abs(ly) if ly < 0 else 0
        pad_y_r = (uy - H) if uy > H else 0
        pad_x_l = abs(lx) if lx < 0 else 0
        pad_x_r = (ux - W) if ux > W else 0
        
        if (pad_x_l+pad_x_r+pad_y_l+pad_y_r+pad_z_l+pad_z_r) > 0:
            # F.padé¡ºåº: x_l, x_r, y_l, y_r, z_l, z_r
            patch = torch.nn.functional.pad(patch, (pad_x_l, pad_x_r, pad_y_l, pad_y_r, pad_z_l, pad_z_r))

        # ç»Ÿä¸€ Resize (ç¡®ä¿è¾“å‡ºå°ºå¯¸ä¸€è‡´)
        target_size = (64, 64, 64) 
        if patch.shape[2:] != target_size:
            patch = torch.nn.functional.interpolate(patch, size=target_size, mode='trilinear', align_corners=False)
            
        cropedDICOMs.append(patch)

    return cropedDICOMs

def getcropedInputs(ROIs, inputs_origin, cropSize, useGPU):
    # ROIs: (1, N, 3) ç»å¯¹åƒç´ åæ ‡ (å·²åœ¨ MyDataLoader ä¸­é’³ä½)
    # inputs_origin: (B, C, D, H, W)
    
    landmarks = ROIs
    landmarkNum = landmarks.shape[1]
    b, c, l, h, w = inputs_origin.size()

    # cropSize ä¼ å…¥çš„æ˜¯ç›´å¾„ (96)ï¼Œè®¡ç®—åŠå¾„
    radius = int(cropSize / 2)
    
    # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šç›´æ¥ä½¿ç”¨åƒç´ åæ ‡ï¼Œç§»é™¤ * (h-1) çš„ç¼©æ”¾
    X = landmarks[:, :, 0]
    Y = landmarks[:, :, 1]
    Z = landmarks[:, :, 2]
    
    # è½¬æ•´å‹
    X = np.round(X).astype("int")
    Y = np.round(Y).astype("int")
    Z = np.round(Z).astype("int")
    
    cropedDICOMs = []
    
    for landmarkId in range(landmarkNum):
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾è¾“å…¥çš„ ROIs é¡ºåºæ˜¯ (X, Y, Z) å¯¹åº” (H, W, D) è¿˜æ˜¯ (D, H, W)?
        # æ ¹æ®ä¹‹å‰çš„æŠ¥é”™ "allocate ... uy - w"ï¼Œä»¥åŠ MyDataLoader é‡Œçš„ reshape
        # æˆ‘ä»¬å‡è®¾è¾“å…¥é¡ºåºå·²ç»é€‚é…äº†
        
        # MyDataLoader ä¼ å…¥çš„æ˜¯ (D, H, W) å¯¹åº”çš„åæ ‡
        # åŸä»£ç çœ‹èµ·æ¥ X å¯¹åº” h, Y å¯¹åº” w, Z å¯¹åº” l
        z, x, y = Z[0][landmarkId], X[0][landmarkId], Y[0][landmarkId]
        
        lz, uz = z - radius, z + radius
        lx, ux = x - radius, x + radius
        ly, uy = y - radius, y + radius
        
        # è®¡ç®—æœ‰æ•ˆåŒºåŸŸ (Clamp)
        lzz, uzz = max(lz, 0), min(uz, l)
        lxx, uxx = max(lx, 0), min(ux, h)
        lyy, uyy = max(ly, 0), min(uy, w)

        # åˆ‡å–æœ‰æ•ˆéƒ¨åˆ†
        cropedDICOM = inputs_origin[:, :, lzz: uzz, lxx: uxx, lyy: uyy].clone()
        
        # Padding é€»è¾‘ (å¤„ç†è¾¹ç¼˜)
        # å¦‚æœ MyDataLoader å·²ç»åšäº† Safe Clampï¼Œè¿™é‡Œå…¶å®ä¸ä¼šè§¦å‘ Padding
        # ä½†ä¿ç•™ä»¥é˜²ä¸‡ä¸€
        
        # Zè½´ padding
        if lz < 0:
            pad = torch.zeros(b, c, 0 - lz, cropedDICOM.size(3), cropedDICOM.size(4)).to(inputs_origin.device)
            cropedDICOM = torch.cat((pad, cropedDICOM), 2)
        if uz > l:
            pad = torch.zeros(b, c, uz - l, cropedDICOM.size(3), cropedDICOM.size(4)).to(inputs_origin.device)
            cropedDICOM = torch.cat((cropedDICOM, pad), 2)
            
        # Xè½´ padding
        if lx < 0:
            pad = torch.zeros(b, c, cropedDICOM.size(2), 0 - lx, cropedDICOM.size(4)).to(inputs_origin.device)
            cropedDICOM = torch.cat((pad, cropedDICOM), 3)
        if ux > h:
            pad = torch.zeros(b, c, cropedDICOM.size(2), ux - h, cropedDICOM.size(4)).to(inputs_origin.device)
            cropedDICOM = torch.cat((cropedDICOM, pad), 3)
            
        # Yè½´ padding
        if ly < 0:
            pad = torch.zeros(b, c, cropedDICOM.size(2), cropedDICOM.size(3), 0 - ly).to(inputs_origin.device)
            cropedDICOM = torch.cat((pad, cropedDICOM), 4)
        if uy > w:
            pad = torch.zeros(b, c, cropedDICOM.size(2), cropedDICOM.size(3), uy - w).to(inputs_origin.device)
            cropedDICOM = torch.cat((cropedDICOM, pad), 4)

        cropedDICOMs.append(cropedDICOM)

    return cropedDICOMs

def get_local_patches(ROIs, cropedtems, base_coordinate, usegpu):
    local_coordinate = []
    local_patches = []
    for i in range(len(cropedtems)):
        centre = torch.from_numpy(ROIs[0, i, :]).cuda(usegpu)
        tem = base_coordinate + centre
        local_coordinate.append(tem)
    local_patches = cropedtems
    return local_patches, local_coordinate

def getCroped(ROIs, outputs):
    # imageNum, landmarkNum * channels, Long, Height, Width
    Y1, Y2, Y3 = outputs[1], outputs[2], outputs[3]
    size1, size2, size3 = Y1.size()[2:], Y2.size()[2:], Y3.size()[2:]
    print(size1, size2, size3)

def resizeDICOM(DICOM, shape_DICOM):
    l, h, w = DICOM.shape[:3]
    newl, newh, neww = shape_DICOM
    scalel, scaleh, scalew = newl / l, newh / h, neww / w

    newDICOM = zoom(DICOM, (scalel, scaleh, scalew))
    print(newDICOM.shape)
    return newDICOM

def showDICOM(DICOM, label, predict, epoch, lent):

    # import pdb
    # pdb.set_trace()

    x, y, z = int(label[0] * 767), int(label[1] * 767), int(label[2] * 575)
    xx, yy, zz = int(predict[0] * 767), int(predict[1] * 767), int(predict[2] * 575)

    imageX = DICOM[:, x, :]
    imageY = DICOM[:, :, y]
    imageZ = DICOM[z, :, :]
    # ~ print (x, y, z)
    # ~ print ("imageX", imageX.shape)
    # ~ print ("imageY", imageY.shape)
    # ~ print ("imageZ", imageZ.shape)

    minvX, maxvX = np.min(imageX), np.max(imageX)
    minvY, maxvY = np.min(imageY), np.max(imageY)
    minvZ, maxvZ = np.min(imageZ), np.max(imageZ)

    imageX = (imageX - minvX) / (maxvX - minvX) * 255
    imageY = (imageY - minvY) / (maxvY - minvY) * 255
    imageZ = (imageZ - minvZ) / (maxvZ - minvZ) * 255

    imageX = Image.fromarray(imageX.astype('uint8'))
    imageX = imageX.convert('RGB')
    drawX = ImageDraw.Draw(imageX)

    imageY = Image.fromarray(imageY.astype('uint8'))
    imageY = imageY.convert('RGB')
    drawY = ImageDraw.Draw(imageY)

    imageZ = Image.fromarray(imageZ.astype('uint8'))



    imageZ = imageZ.convert('RGB')
    drawZ = ImageDraw.Draw(imageZ)
    r = int(DICOM.shape[0] / 80)


    positionX = (y - r, z - r, y + r, z + r)
    positionY = (x - r, z - r, x + r, z + r)
    positionZ = (y - r, x - r, y + r, x + r)

    positionXX = (yy - r, zz - r, yy + r, zz + r)
    positionYY = (xx - r, zz - r, xx + r, zz + r)
    positionZZ = (yy - r, xx - r, yy + r, xx + r)

    drawX.ellipse(positionXX, fill=(255, 0, 0))
    drawY.ellipse(positionYY, fill=(255, 0, 0))
    drawZ.ellipse(positionZZ, fill=(255, 0, 0))

    drawX.ellipse(positionX, fill=(0, 255, 0))
    drawY.ellipse(positionY, fill=(0, 255, 0))
    drawZ.ellipse(positionZ, fill=(0, 255, 0))


    imageX.save("vis_images/" + str(lent) + "_" + str(epoch) + "_imageX.jpg")
    imageY.save("vis_images/" + str(lent) + "_" + str(epoch) + "_imageY.jpg")
    imageZ.save("vis_images/" + str(lent) + "_" + str(epoch) + "_imageZ.jpg")

    # plt.suptitle("multi_image")
    # plt.subplot(1, 3, 1), plt.title("x")
    # plt.imshow(imageX, cmap='gray', interpolation='nearest'), plt.axis("off")
    # plt.subplot(1, 3, 2), plt.title("y")
    # plt.imshow(imageY, cmap='gray', interpolation='nearest'), plt.axis("off")
    # plt.subplot(1, 3, 3), plt.title("z")
    # plt.imshow(imageZ, cmap='gray', interpolation='nearest')
    # plt.savefig("filename.png")
    # print("filename.png")
    # plt.show()
    # dfdf = input()

def drawImage(image, coordindates_before, coordindates_after):
    # image = image_before
    # image = Image.fromarray((image * 255).astype('uint8'))
    draw = ImageDraw.Draw(image)
    font = ImageFont.truetype("/usr/share/fonts/truetype/freefont/FreeMonoBold.ttf", 15)
    t = 0

    for ide in range(68):
        r = 6
        t = t + 1
        # draw.rectangle(coordindates_before, outline = "red")
        # x, y = coordindates_after[ide]['x'], coordindates_after[ide]['y']
        x, y = coordindates_after[ide][0], coordindates_after[ide][1]
        position = (x - r, y - r, x + r, y + r)

        # draw.ellipse(position,fill = (0, 255, 0))

        draw.text((x, y), str(t), fill=(0, 255, 255), font=font)

    plt.imshow(image, cmap='gray', interpolation='nearest')
    image.save("compare.png")
    fdf = input()


# return image
def Mydist(a, b):
    x1, y1 = a
    x2, y2 = b
    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)


def Mydist3D(a, b):
    z1, x1, y1 = a
    z2, x2, y2 = b
    return math.sqrt((z2 - z1) ** 2 + (x2 - x1) ** 2 + (y2 - y1) ** 2)

def getcropedInputs(ROIs, inputs_origin, cropSize, useGPU):
    # ROIs: (1, N, 3) ç»å¯¹åƒç´ åæ ‡ (å·²åœ¨ MyDataLoader ä¸­é’³ä½)
    # inputs_origin: (B, C, D, H, W)
    
    landmarks = ROIs
    landmarkNum = landmarks.shape[1]
    b, c, l, h, w = inputs_origin.size()

    # cropSize ä¼ å…¥çš„æ˜¯ç›´å¾„ (96)ï¼Œè®¡ç®—åŠå¾„
    radius = int(cropSize / 2)
    
    # ğŸ”¥ å…³é”®ä¿®æ”¹ï¼šç›´æ¥ä½¿ç”¨åƒç´ åæ ‡ï¼Œç§»é™¤ * (h-1) çš„ç¼©æ”¾
    X = landmarks[:, :, 0]
    Y = landmarks[:, :, 1]
    Z = landmarks[:, :, 2]
    
    # è½¬æ•´å‹
    X = np.round(X).astype("int")
    Y = np.round(Y).astype("int")
    Z = np.round(Z).astype("int")
    
    cropedDICOMs = []
    
    for landmarkId in range(landmarkNum):
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾è¾“å…¥çš„ ROIs é¡ºåºæ˜¯ (X, Y, Z) å¯¹åº” (H, W, D) è¿˜æ˜¯ (D, H, W)?
        # æ ¹æ®ä¹‹å‰çš„æŠ¥é”™ "allocate ... uy - w"ï¼Œä»¥åŠ MyDataLoader é‡Œçš„ reshape
        # æˆ‘ä»¬å‡è®¾è¾“å…¥é¡ºåºå·²ç»é€‚é…äº†
        
        # MyDataLoader ä¼ å…¥çš„æ˜¯ (D, H, W) å¯¹åº”çš„åæ ‡
        # åŸä»£ç çœ‹èµ·æ¥ X å¯¹åº” h, Y å¯¹åº” w, Z å¯¹åº” l
        z, x, y = Z[0][landmarkId], X[0][landmarkId], Y[0][landmarkId]
        
        lz, uz = z - radius, z + radius
        lx, ux = x - radius, x + radius
        ly, uy = y - radius, y + radius
        
        # è®¡ç®—æœ‰æ•ˆåŒºåŸŸ (Clamp)
        lzz, uzz = max(lz, 0), min(uz, l)
        lxx, uxx = max(lx, 0), min(ux, h)
        lyy, uyy = max(ly, 0), min(uy, w)

        # åˆ‡å–æœ‰æ•ˆéƒ¨åˆ†
        cropedDICOM = inputs_origin[:, :, lzz: uzz, lxx: uxx, lyy: uyy].clone()
        
        # Padding é€»è¾‘ (å¤„ç†è¾¹ç¼˜)
        # å¦‚æœ MyDataLoader å·²ç»åšäº† Safe Clampï¼Œè¿™é‡Œå…¶å®ä¸ä¼šè§¦å‘ Padding
        # ä½†ä¿ç•™ä»¥é˜²ä¸‡ä¸€
        
        # Zè½´ padding
        if lz < 0:
            pad = torch.zeros(b, c, 0 - lz, cropedDICOM.size(3), cropedDICOM.size(4)).to(inputs_origin.device)
            cropedDICOM = torch.cat((pad, cropedDICOM), 2)
        if uz > l:
            pad = torch.zeros(b, c, uz - l, cropedDICOM.size(3), cropedDICOM.size(4)).to(inputs_origin.device)
            cropedDICOM = torch.cat((cropedDICOM, pad), 2)
            
        # Xè½´ padding
        if lx < 0:
            pad = torch.zeros(b, c, cropedDICOM.size(2), 0 - lx, cropedDICOM.size(4)).to(inputs_origin.device)
            cropedDICOM = torch.cat((pad, cropedDICOM), 3)
        if ux > h:
            pad = torch.zeros(b, c, cropedDICOM.size(2), ux - h, cropedDICOM.size(4)).to(inputs_origin.device)
            cropedDICOM = torch.cat((cropedDICOM, pad), 3)
            
        # Yè½´ padding
        if ly < 0:
            pad = torch.zeros(b, c, cropedDICOM.size(2), cropedDICOM.size(3), 0 - ly).to(inputs_origin.device)
            cropedDICOM = torch.cat((pad, cropedDICOM), 4)
        if uy > w:
            pad = torch.zeros(b, c, cropedDICOM.size(2), cropedDICOM.size(3), uy - w).to(inputs_origin.device)
            cropedDICOM = torch.cat((cropedDICOM, pad), 4)

        cropedDICOMs.append(cropedDICOM)

    return cropedDICOMs

# ä½¿ç”¨logæ¥è®°å½•ï¼ŒåŒæ—¶å»ºç«‹ä¸¤æ¡é€šé“ï¼Œä¸€æ¡é€šå¾€.logæ–‡ä»¶ï¼Œä¸€æ¡é€šå¾€å±å¹•
def get_logger(filename, verbosity=1, name=None):
    """
    åˆ›å»ºä¸€ä¸ªæ—¥å¿—è®°å½•å™¨ logger
    :param filename: æ—¥å¿—æ–‡ä»¶ä¿å­˜è·¯å¾„ (ä¾‹å¦‚: runs/exp1/train.log)
    :param verbosity: æ—¥å¿—çº§åˆ«
    :param name: logger çš„åå­—
    :return: é…ç½®å¥½çš„ logger å¯¹è±¡
    """
    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}
    formatter = logging.Formatter(
        "[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s"
    )
    
    logger = logging.getLogger(name)
    logger.setLevel(level_dict[verbosity])
    
    # 1. File Handler (å†™å…¥æ–‡ä»¶)
    fh = logging.FileHandler(filename, "w", encoding='utf-8')
    fh.setFormatter(formatter)
    logger.addHandler(fh)
    
    # 2. Stream Handler (è¾“å‡ºåˆ°ç»ˆç«¯/å±å¹•)
    sh = logging.StreamHandler(sys.stdout)
    sh.setFormatter(formatter)
    logger.addHandler(sh)
    
    return logger

class GPUAugmentor:
    """
    åœ¨ GPU ä¸Šå¯¹ 3D å›¾åƒè¿›è¡Œå®æ—¶å¢å¼º (æ—‹è½¬ã€ç¼©æ”¾ã€å¼ºåº¦å˜æ¢)
    """
    def __init__(self, device, angle_range=(-10, 10), scale_range=(0.9, 1.1)):
        self.device = device
        self.angle_range = angle_range
        self.scale_range = scale_range

    def __call__(self, images, landmarks):
        """
        :param images: (B, 1, D, H, W) Tensor
        :param landmarks: (B, N, 3) Tensor, åæ ‡é¡ºåºå¿…é¡»æ˜¯ (z, y, x) å¯¹åº” (D, H, W)
        """
        current_device = images.device
        B, C, D, H, W = images.shape
        
        # --- 1. éšæœºå‚æ•°ç”Ÿæˆ ---
        # TODO:æ—‹è½¬è§’åº¦ (å¼§åº¦) - ç›®å‰åªåš Z è½´æ—‹è½¬ (å¹³é¢å†…æ—‹è½¬)ï¼Œè¿™æ˜¯æœ€å…³é”®çš„
        angles = (torch.rand(B, device=current_device) * (self.angle_range[1] - self.angle_range[0]) + self.angle_range[0])
        rads = torch.deg2rad(-angles) # å–åé€‚é… grid_sample æ–¹å‘

        # ç¼©æ”¾å› å­
        scales = (torch.rand(B, device=current_device) * (self.scale_range[1] - self.scale_range[0]) + self.scale_range[0])

        # --- 2. æ„å»ºä»¿å°„å˜æ¢çŸ©é˜µ (B, 3, 4) ---
        # ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªçŸ©é˜µï¼Œå°†åƒç´ ç½‘æ ¼è¿›è¡Œæ—‹è½¬å’Œç¼©æ”¾
        theta = torch.zeros(B, 3, 4, device=current_device)
        
        cos_a = torch.cos(rads)
        sin_a = torch.sin(rads)

        # ç¼©æ”¾ + æ—‹è½¬ (ç»• D è½´ / Z è½´)
        # çŸ©é˜µç»“æ„:
        # [ sc,  0,   0,   0 ]
        # [ 0,   c*s, -s*s, 0 ]
        # [ 0,   s*s, c*s, 0 ]
        
        # D è½´ (Depth) åªç¼©æ”¾ï¼Œä¸æ—‹è½¬
        theta[:, 0, 0] = scales 
        
        # H, W å¹³é¢ (Height, Width) è¿›è¡Œæ—‹è½¬ + ç¼©æ”¾
        theta[:, 1, 1] = scales * cos_a
        theta[:, 1, 2] = -scales * sin_a * (W / H) # ä¿®æ­£å®½é«˜æ¯”ï¼Œé˜²æ­¢æ—‹è½¬åå˜å½¢
        theta[:, 2, 1] = scales * sin_a * (H / W)
        theta[:, 2, 2] = scales * cos_a

        # --- 3. åº”ç”¨å‡ ä½•å˜æ¢ (Grid Sample) ---
        grid = F.affine_grid(theta, images.size(), align_corners=False)
        aug_images = F.grid_sample(images, grid, mode='bilinear', padding_mode='zeros', align_corners=False)

        # --- 4. åº”ç”¨å…³é”®ç‚¹å˜æ¢ (çŸ©é˜µä¹˜æ³•) ---
        # å…³é”®ç‚¹æ—‹è½¬ä¸­å¿ƒ (å›¾åƒä¸­å¿ƒ)
        center = torch.tensor([D/2, H/2, W/2], device=current_device)
        
        # æ„é€ å¯¹åº”çš„æ—‹è½¬çŸ©é˜µ R (B, 3, 3)
        R = torch.zeros(B, 3, 3, device=current_device)
        R[:, 0, 0] = 1 
        R[:, 1, 1] = cos_a
        R[:, 1, 2] = -sin_a
        R[:, 2, 1] = sin_a
        R[:, 2, 2] = cos_a
        
        # åæ ‡å˜æ¢å…¬å¼: (P - Center) @ R.T * Scale + Center
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ˜¯åœ¨ç‰©ç†åæ ‡ç³»ä¸‹æ“ä½œï¼Œä¸éœ€è¦åƒ grid_sample é‚£æ ·è€ƒè™‘å®½é«˜æ¯”ä¿®æ­£
        landmarks = (landmarks - center)
        landmarks = torch.bmm(landmarks, R.transpose(1, 2)) 
        landmarks = landmarks * scales.unsqueeze(1).unsqueeze(2) + center

        # --- 5. å¼ºåº¦/å¯¹æ¯”åº¦å˜æ¢ (Intensity Shift) ---
        if torch.rand(1) < 0.5:
            contrast = torch.rand(B, 1, 1, 1, 1, device=current_device) * 0.4 + 0.8 # 0.8 ~ 1.2
            brightness = torch.rand(B, 1, 1, 1, 1, device=current_device) * 0.2 - 0.1 # -0.1 ~ 0.1
            aug_images = aug_images * contrast + brightness
            aug_images = torch.clamp(aug_images, 0.0, 1.0) # ä¿æŒå½’ä¸€åŒ–

        return aug_images, landmarks
    
# ä¸€é”®å¤„ç†å‡½æ•° (Clean Wrapper)
def prepare_batch_input(data, config, phase, augmentor=None):
    """
    è¾“å…¥åŸå§‹ Batch æ•°æ®ï¼Œè¾“å‡ºæ¨¡å‹å¯ç›´æ¥ç”¨çš„ Coarseè¾“å…¥ å’Œ Fineè¾“å…¥
    """
    # 1. æ¬è¿åˆ° GPU
    inputs_origin = data['DICOM_origin'].cuda(config.use_gpu) # (B, D, H, W)
    if len(inputs_origin.shape) == 3: inputs_origin = inputs_origin.unsqueeze(0).unsqueeze(0)
    elif len(inputs_origin.shape) == 4: inputs_origin = inputs_origin.unsqueeze(1) # (B, 1, D, H, W)
    
    labels = data['landmarks'].cuda(config.use_gpu).float()

    # 2. è®­ç»ƒé˜¶æ®µæ‰§è¡Œå¢å¼º
    if phase == 'train' and augmentor is not None:
        inputs_origin, labels = augmentor(inputs_origin, labels)
        
        # å®‰å…¨é’³ä½
        D, H, W = inputs_origin.shape[2:]
        labels[:, :, 0] = torch.clamp(labels[:, :, 0], 0, D-1)
        labels[:, :, 1] = torch.clamp(labels[:, :, 1], 0, H-1)
        labels[:, :, 2] = torch.clamp(labels[:, :, 2], 0, W-1)

    # 3. GPU ç”Ÿæˆ Coarse è¾“å…¥ (ä¸‹é‡‡æ ·)
    inputs_coarse = torch.nn.functional.interpolate(inputs_origin, size=config.image_scale, mode='trilinear', align_corners=False)

    # 4. æ ¼å¼é€‚é… (Hack)
    # å› ä¸ºä½ çš„ fine_LSTM å†…éƒ¨è¿˜åœ¨ç”¨ CPU åˆ‡å›¾ï¼Œæˆ‘ä»¬éœ€è¦æŠŠå¢å¼ºåçš„é«˜æ¸…å›¾è½¬å› CPU list
    # è™½ç„¶å¤šäº†ä¸€æ­¥ä¼ è¾“ï¼Œä½†ä¾ç„¶æ¯” CPU æ—‹è½¬å¿«å¾—å¤š
    inputs_origin_list = [inputs_origin[i].detach().cpu() for i in range(inputs_origin.shape[0])]

    _, _, D, H, W = inputs_origin.shape

    size_tensor = torch.tensor([D, H, W], device=labels.device).float()

    labels = labels / size_tensor

    return inputs_coarse, inputs_origin_list, labels