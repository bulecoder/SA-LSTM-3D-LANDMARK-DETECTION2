import torch
import os
import numpy as np
import pandas as pd
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm
import argparse

# å¼•å…¥é¡¹ç›®æ¨¡å—
from MyModel import coarseNet
from MyDataLoader import LandmarksDataset, ToTensor
import MyUtils 

# ==========================================
# é…ç½®å‚æ•°
# ==========================================
parser = argparse.ArgumentParser()
parser.add_argument("--batchSize", type=int, default=1)
parser.add_argument("--landmarkNum", type=int, default=7) 
parser.add_argument("--image_scale", default=(96, 96, 96), type=tuple) # (D, H, W)
parser.add_argument("--use_gpu", type=int, default=1)
parser.add_argument("--testcsv", type=str, default='test.csv') 
parser.add_argument("--data_enhanceNum", type=int, default=1) 
parser.add_argument("--spacing", default=(0.5, 0.5, 0.5), type=tuple)
parser.add_argument("--saveName", type=str, default='test3')   

def evaluate_all(config):
    print(f"ğŸš€ å¼€å§‹å…¨é‡è¯„ä¼° CoarseNet (æƒé‡: {config.saveName})...")
    device = torch.device("cuda" if config.use_gpu else "cpu")
    
    # 1. å‡†å¤‡æ•°æ®
    transform_test = transforms.Compose([ToTensor()])
    dataset_path = "F:/CBCT/SA-LSTM-3D-Landmark-Detection2/processed_data/"
    
    test_dataset = LandmarksDataset(
        csv_file=dataset_path + config.testcsv,
        root_dir=dataset_path + "images",
        transform=transform_test,
        landmarksNum=config.landmarkNum
    )
    dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)
    
    # 2. åŠ è½½æ¨¡å‹
    model = coarseNet(config).to(device)
    model_path = os.path.join('runs', config.saveName, 'best_coarse.pth')
    
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path))
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
    else:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æƒé‡æ–‡ä»¶ {model_path}")
        return

    model.eval()
    
    # 3. æ„å»º Global Coordinate (å®Œå…¨å¤åˆ» TrainNet)
    gl, gh, gw = config.image_scale
    global_coordinate = torch.ones(gl, gh, gw, 3).float()
    
    for i in range(gl):
        global_coordinate[i, :, :, 0] = global_coordinate[i, :, :, 0] * i
    for i in range(gh):
        global_coordinate[:, i, :, 1] = global_coordinate[:, i, :, 1] * i
    for i in range(gw):
        global_coordinate[:, :, i, 2] = global_coordinate[:, :, i, 2] * i
        
    global_coordinate = global_coordinate.to(device) * torch.tensor([1 / (gl - 1), 1 / (gh - 1), 1 / (gw - 1)]).to(device)

    all_errors_mm = [] 
    
    print("\nğŸ“Š æ­£åœ¨é€ä¸ªæ ·æœ¬æ¨ç†...")
    print(f"{'Sample ID':<20} | {'MRE (mm)':<15} | {'Physical Scale (mm)':<30}")
    print("-" * 80)

    with torch.no_grad():
        for i, data in enumerate(dataloader):
            inputs = data['DICOM'].to(device)
            labels = data['landmarks'].to(device) # (B, N, 3) Truth [0-1]
            
            # --- ğŸ”¥ ä¿®æ­£ï¼šè®¡ç®—ç‰©ç†å°ºå¯¸ (mm) ğŸ”¥ ---
            try:
                # data['size'] æ˜¯ Tensor å½¢çŠ¶ (Batch, 3) -> (1, 3)
                # æˆ‘ä»¬å…ˆå–å‡ºç¬¬ 0 ä¸ªæ ·æœ¬çš„æ•°æ®
                size_data = data['size'][0] # å˜æˆ Tensor([512, 512, 512])
                
                # ç°åœ¨å¯ä»¥ç›´æ¥æŒ‰ç´¢å¼• 0, 1, 2 å–å€¼äº†
                # å‡è®¾ Dataset è¿”å›é¡ºåºæ˜¯ [Depth, Height, Width]
                pixel_z = size_data[0].item() # 512
                pixel_y = size_data[1].item() # 512
                pixel_x = size_data[2].item() # 512
                
                # 2. è·å– Spacing [z, y, x]
                sp_z, sp_y, sp_x = config.spacing # (0.4, 0.4, 0.4)
                
                # 3. æ„å»ºç‰©ç† Scale å‘é‡ (mm)
                scale_w = pixel_x * sp_x # Width (mm)
                scale_h = pixel_y * sp_y # Height (mm)
                scale_d = pixel_z * sp_z # Depth (mm)
                
                # âš ï¸ æ³¨æ„è¿™é‡Œé¡ºåº: [Width, Height, Depth]
                physical_scale = np.array([scale_w, scale_h, scale_d])
                
            except Exception as e:
                print(f"âš ï¸ Scale è®¡ç®—å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤ 204.8mm")
                physical_scale = np.array([204.8, 204.8, 204.8])

            # A. æ¨ç†
            pred_heatmaps_list, _ = model(inputs)
            
            # B. è®¡ç®—åæ ‡
            # pred_coords: (1, N, 3) -> [x, y, z] (MyUtilså·²ä¿®å¤)
            pred_coords = MyUtils.get_coordinates_from_coarse_heatmaps(pred_heatmaps_list, global_coordinate)
            
            # C. è®¡ç®—è¯¯å·®
            # è¿‡æ»¤æ— æ•ˆç‚¹
            mask = (labels[:, :, 0] >= 0).cpu().numpy()
            
            diff = torch.abs(pred_coords - labels).cpu().numpy() # (1, N, 3) [0-1]
            
            # è¿˜åŸç‰©ç†å°ºå¯¸ (mm)
            # è¯¯å·® = å½’ä¸€åŒ–å·®å€¼ * ç‰©ç†å…¨å°ºå¯¸(mm)
            diff_mm = diff * physical_scale
            
            # è®¡ç®—æ¬§æ°è·ç¦»
            dist_mm = np.linalg.norm(diff_mm, axis=2) # (1, N)
            
            # åªç»Ÿè®¡æœ‰æ•ˆç‚¹
            valid_dists = dist_mm[mask]
            
            all_errors_mm.extend(valid_dists)
            
            # æ‰“å°å½“å‰æ ·æœ¬å‡å€¼
            sample_mre = np.mean(valid_dists) if len(valid_dists) > 0 else 0
            
            sample_name = data['imageName'][0]
            
            # æ ¼å¼åŒ– scale å­—ç¬¦ä¸²æ–¹ä¾¿æ£€æŸ¥
            scale_str = f"[{physical_scale[0]:.1f}, {physical_scale[1]:.1f}, {physical_scale[2]:.1f}]"
            
            print(f"{sample_name[:20]:<20} | {sample_mre:<15.4f} | {scale_str:<30}")

    # 4. æœ€ç»ˆæ±‡æ€»
    print("\n" + "="*50)
    print("ğŸ“ˆ å…¨é‡è¯„ä¼°æŠ¥å‘Š (Coarse Stage Only)")
    print("="*50)
    
    if len(all_errors_mm) == 0:
        print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆå…³é”®ç‚¹ï¼")
        return

    mre = np.mean(all_errors_mm)
    sd = np.std(all_errors_mm)
    max_e = np.max(all_errors_mm)
    
    print(f"Total Valid Landmarks : {len(all_errors_mm)}")
    print("-" * 30)
    print(f"MRE (Mean Radial Error): {mre:.4f} mm")
    print(f"SD  (Standard Deviation): {sd:.4f} mm")
    print(f"Max Error               : {max_e:.4f} mm")
    print("="*50)

if __name__ == '__main__':
    config = parser.parse_args()
    evaluate_all(config)