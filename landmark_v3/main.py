import os
import torch
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader
import warnings

# --- å¼•ç”¨é‡æ„åçš„æ¨¡å— ---
from config import Config
from models import legacy_models as MyModel
from data import legacy_dataset as MyDataLoader
from core import legacy_loss as LossFunction
from core.legacy_trainer import Trainer

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning)

def main():
    # 1. åŠ è½½é…ç½®
    config = Config().parse()
    
    print(f"ğŸš€ Start Mode: {config.stage.upper()}")
    
    # 2. åˆå§‹åŒ–æ¨¡å‹
    # æ³¨æ„ï¼šæ—§ä»£ç é‡Œæ˜¯ MyModel.fine_LSTM(config) å’Œ MyModel.coarseNet(config)
    fine_LSTM = MyModel.fine_LSTM(config).cuda(config.use_gpu)
    coarseNet = MyModel.coarseNet(config).cuda(config.use_gpu)

    # 3. æ•°æ®é¢„å¤„ç†
    transform_origin = transforms.Compose([
        MyDataLoader.ToTensor()
    ])

    # --- TEST æ¨¡å¼ ---
    if config.stage == 'test':
        print(f"ğŸš€ Loading weights from: {config.testName}")
        save_dir = os.path.join('runs', config.testName)
        
        # åŠ è½½æƒé‡
        coarse_path = os.path.join(save_dir, 'best_coarse.pth')
        fine_path = os.path.join(save_dir, 'best_fine_LSTM.pth')
        
        if os.path.exists(coarse_path) and os.path.exists(fine_path):
            coarseNet.load_state_dict(torch.load(coarse_path))
            fine_LSTM.load_state_dict(torch.load(fine_path))
        else:
            print(f"âŒ Error: Weights not found in {save_dir}")
            return

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_dataset = MyDataLoader.LandmarksDataset(
            csv_file=config.dataRoot + config.testcsv,
            root_dir=config.dataRoot + "images",
            transform=transform_origin,
            landmarksNum=config.landmarkNum,
        )
        # æµ‹è¯•ç”¨ DataLoader (æ—§ä»£ç è¿™é‡Œæ²¡æœ‰è½¬ listï¼Œç›´æ¥ç”¨çš„ DataLoader)
        test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)
        
        # åˆå§‹åŒ– Trainer (ä¸ºäº†è°ƒç”¨ test æ–¹æ³•)
        # æµ‹è¯•æ¨¡å¼ä¸‹ loss å’Œ optimizer å¯ä»¥ä¸ºç©º
        trainer = Trainer(config, coarseNet, fine_LSTM, {'val': test_dataloader}, None, None, None)
        trainer.test()
        return

    # --- TRAIN æ¨¡å¼ ---
    
    # 4. å‡†å¤‡æ•°æ®é›†
    train_dataset = MyDataLoader.LandmarksDataset(
        csv_file=config.dataRoot + config.traincsv,
        root_dir=config.dataRoot + "images",
        transform=transform_origin,
        landmarksNum=config.landmarkNum
    )

    val_dataset = MyDataLoader.LandmarksDataset(
        csv_file=config.dataRoot + config.testcsv,
        root_dir=config.dataRoot + "images",
        transform=transform_origin,
        landmarksNum=config.landmarkNum
    )
    
    # 5. ğŸ”¥ å¤åˆ»æ—§é€»è¾‘ï¼šæŠŠ DataLoader è½¬ä¸º List (è™½ç„¶å¾ˆè€—å†…å­˜ï¼Œä½†ä¸ºäº†ä¿æŒä¸€è‡´)
    # æ—§ä»£ç :
    # train_dataloader_t = DataLoader(..., shuffle=False)
    # for data in train_dataloader_t: train_dataloader.append(data)
    
    train_loader_raw = DataLoader(train_dataset, batch_size=config.batchSize, shuffle=False, num_workers=0)
    val_loader_raw = DataLoader(val_dataset, batch_size=config.batchSize, shuffle=False, num_workers=0)
    
    train_data_list = []
    print("â³ Pre-loading Training Data into RAM (Legacy Mode)...")
    for data in train_loader_raw:
        train_data_list.append(data)
        
    val_data_list = []
    print("â³ Pre-loading Validation Data into RAM (Legacy Mode)...")
    for data in val_loader_raw:
        val_data_list.append(data)
        
    print(f"âœ… Loaded: Train {len(train_data_list)}, Val {len(val_data_list)}")
    
    dataloaders = {'train': train_data_list, 'val': val_data_list}

    # 6. åˆå§‹åŒ– Loss å’Œ Optimizer
    criterion_coarse = LossFunction.coarse_heatmap(config).cuda(config.use_gpu)
    criterion_fine = LossFunction.fine_heatmap(config).cuda(config.use_gpu) # è¿™é‡Œçš„fine_heatmapå¯èƒ½æ²¡ç”¨ä¸Šï¼Œå› ä¸ºæ—§ Trainer é‡Œæ‰‹å†™äº† SmoothL1ï¼Œä½†ä¸ºäº†å…¼å®¹å…ˆä¼ è¿›å»

    params = list(coarseNet.parameters()) + list(fine_LSTM.parameters())
    optimizer = optim.AdamW(params, lr=config.lr, weight_decay=5e-4)

    # 7. å¯åŠ¨ Trainer
    trainer = Trainer(config, coarseNet, fine_LSTM, dataloaders, criterion_coarse, criterion_fine, optimizer)
    trainer.run()

if __name__ == "__main__":
    main()