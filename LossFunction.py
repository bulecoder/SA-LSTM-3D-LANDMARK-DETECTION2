from __future__ import print_function, division
import torch
import torch.nn as nn
from torch.autograd import Variable
import numpy as np
import math
import math
import MyUtils
import torch.nn.functional as F

def vae_loss(recon_x, x, mu, logvar):

    #print (recon_x.view(-1))
    #BCE = F.binary_cross_entropy(recon_x.view(1,-1), x.view(1,-1), size_average = False)
    # BCE = F.mse_loss(recon_x.view(1,-1), x.view(1,-1), size_average = False)
    BCE = F.l1_loss(recon_x.view(1,-1), x.view(1,-1), size_average = False)
    # see Appendix B from VAE paper:
    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014
    # https://arxiv.org/abs/1312.6114
    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())

    # return BCE + KLD
    return BCE


class attentionLoss(nn.Module):
    def __init__(self, gpu):
        super(attentionLoss, self).__init__()
        self.lossFun = torch.nn.L1Loss(size_average=False)
        self.gpu = gpu
        self.delta = torch.tensor([0.]).cuda(self.gpu)

    def forward(self, coormeanAngles, labelsAngles, attention):
        topN = coormeanAngles.size()[0]
        topkP, indexs = torch.topk(attention, topN)
        indexs = indexs.cpu().numpy()
        loss = 0
        alll = 0
        for i in range(topN):
            temp = attention[indexs[i]]
            alll += temp
            # ~ temp = 1
            loss += temp * self.lossFun(coormeanAngles[i, :], labelsAngles[i, :])
        # ~ loss += self.lossFun(1/(torch.var(attention)*1e8 + 1), self.delta)
        # ~ print (alll/topN - 1/ 5456)
        # ~ print (torch.var(attention))
        return loss

# # TODO: ç”¨åˆ°äº†è¿™ä¸ª
# class coarse_heatmap(nn.Module):
#     def __init__(self, config):
#         # use_gpu, batchSize, landmarkNum, image_scale
#         super(coarse_heatmap, self).__init__()
#         self.use_gpu = config.use_gpu
#         self.batchSize = config.batchSize
#         self.landmarkNum = config.landmarkNum
#         self.l1Loss = nn.L1Loss(reduction='none') # æ”¹ä¸º none ä»¥ä¾¿åº”ç”¨ Mask
#         self.Long, self.higth, self.width = config.image_scale # (128, 128, 128)
        
#         # åˆ›å»ºä¸€ä¸ªè¶³å¤Ÿå¤§çš„é«˜æ–¯çƒ­å›¾æ¨¡æ¿ (2å€å°ºå¯¸)
#         self.HeatMap_groundTruth = torch.zeros(self.Long * 2, self.higth * 2, self.width * 2).cuda(self.use_gpu)

#         rr = 21  # åŠå¾„
#         dev = 2  # æ ‡å‡†å·®ï¼ˆsigma)
#         referPoint = (self.Long, self.higth, self.width)  # ä¸­å¿ƒç‚¹
        
#         # é¢„è®¡ç®—é«˜æ–¯åˆ†å¸ƒ
#         # ä¼˜åŒ–ï¼šå¯ä»¥ä½¿ç”¨ç½‘æ ¼ç”Ÿæˆé¿å…ä¸‰é‡å¾ªç¯ï¼Œä½†åªè¿è¡Œä¸€æ¬¡åˆå§‹åŒ–ï¼Œå¿äº†
#         for k in range(referPoint[0] - rr, referPoint[0] + rr + 1):
#             for i in range(referPoint[1] - rr, referPoint[1] + rr + 1):
#                 for j in range(referPoint[2] - rr, referPoint[2] + rr + 1):
#                     temdis = MyUtils.Mydist3D(referPoint, (k, i, j))
#                     if temdis <= rr:
#                         self.HeatMap_groundTruth[k][i][j] = math.exp(-1 * temdis**2 / (2 * dev**2))

#     def forward(self, predicted_heatmap, local_coordinate, labels, phase):
#         # ğŸ” æ£€æŸ¥ CoarseNet è¾“å‡ºçš„çœŸå®å°ºå¯¸
#         sample_map = predicted_heatmap[0] # å–å‡ºç¬¬ä¸€ä¸ªå…³é”®ç‚¹çš„ Batch Tensor
#         print(f"DEBUG: Predicted Heatmap Shape: {sample_map.shape}")
        
#         # ğŸ” æ£€æŸ¥ Config é‡Œçš„å°ºå¯¸
#         print(f"DEBUG: Config Size: {self.Long}, {self.higth}, {self.width}")

#         loss = 0
#         total_valid_points = 0
        
#         # labels shape: (B, N, 3) å½’ä¸€åŒ–åæ ‡ (0~1) æˆ–è€… -1 (ç¼ºå¤±)
        
#         # å°†å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡
#         # x, y, z åˆ†åˆ«å¯¹åº” High, Width, Long (æ³¨æ„è¿™é‡Œçš„é¡ºåºéœ€è¦å’Œ MyDataLoader ä¸€è‡´)
#         # æ ¹æ® MyDataLoaderï¼Œè¾“å…¥æ˜¯ (128, 128, 128)ï¼Œæ‰€ä»¥ä¹˜çš„ç³»æ•°ä¸€æ ·
        
#         # labels_pixel shape: (B, N, 3)
#         scale_tensor = torch.tensor([self.higth - 1, self.width - 1, self.Long - 1]).cuda(self.use_gpu)
#         labels_pixel = labels * scale_tensor
#         labels_pixel = torch.round(labels_pixel).long() # è½¬æ•´æ•°ç´¢å¼•

#         batch_size = labels.shape[0]

#         for b in range(batch_size):
#             # è·å–è¯¥æ ·æœ¬çš„æ‰€æœ‰ç‚¹åæ ‡
#             X = labels_pixel[b, :, 0] # H
#             Y = labels_pixel[b, :, 1] # W
#             Z = labels_pixel[b, :, 2] # D
            
#             # è·å–åŸå§‹å½’ä¸€åŒ–æ ‡ç­¾ç”¨äºåˆ¤æ–­ Mask
#             raw_labels = labels[b]

#             for i in range(self.landmarkNum):
#                 # Mask check: å¦‚æœåæ ‡æ˜¯è´Ÿæ•° (ç¼ºå¤±å€¼)ï¼Œè·³è¿‡
#                 if raw_labels[i, 0] < 0:
#                     continue
                
#                 # é˜²æ­¢è¶Šç•Œ (è™½ç„¶ MyDataLoader é‡Œå¤„ç†äº†ï¼Œä½† safe check å¾ˆé‡è¦)
#                 z_idx = torch.clamp(Z[i], 0, self.Long - 1)
#                 x_idx = torch.clamp(X[i], 0, self.higth - 1)
#                 y_idx = torch.clamp(Y[i], 0, self.width - 1)

#                 # æ ¹æ®çœŸå®ä½ç½®è£å‰ªçƒ­åŠ›å›¾ GT
#                 # é€»è¾‘ï¼šä» HeatMap_groundTruth ä¸­å¿ƒæ‰£å‡ºä¸€å—å’Œé¢„æµ‹å›¾ä¸€æ ·å¤§çš„
#                 # å¦‚æœç‚¹åœ¨å·¦ä¸Šè§’ (0,0,0)ï¼Œå°±å– HeatMap å³ä¸‹éƒ¨åˆ†
#                 # ç´¢å¼•é€»è¾‘æ¯”è¾ƒç»•ï¼Œæ²¿ç”¨åŸä½œè€…æ€è·¯ä½†å¢åŠ å®‰å…¨æ€§
                
#                 # åŸå§‹é€»è¾‘ï¼šself.Long - Z[i]
#                 start_z = self.Long - z_idx
#                 start_x = self.higth - x_idx
#                 start_y = self.width - y_idx
                
#                 coarse_heatmap_gt = self.HeatMap_groundTruth[
#                     start_z : start_z + self.Long,
#                     start_x : start_x + self.higth,
#                     start_y : start_y + self.width
#                 ]
                
#                 # å½’ä¸€åŒ– GT
#                 if coarse_heatmap_gt.sum() > 0:
#                     coarse_heatmap_gt = coarse_heatmap_gt / coarse_heatmap_gt.sum()

#                 # è®¡ç®— L1 Loss
#                 # predicted_heatmap shape: (B, N, D, H, W)
#                 pred = predicted_heatmap[i][b]
                
#                 loss += torch.abs(pred - coarse_heatmap_gt).sum()
#                 total_valid_points += 1
        
#         if total_valid_points > 0:
#             return loss / total_valid_points
#         else:
#             return torch.tensor(0.0).cuda(self.use_gpu)

class coarse_heatmap(nn.Module):
    def __init__(self, config):
        """
        åˆå§‹åŒ–ï¼šä¿æŒä¸åŸä»£ç ä¸€è‡´çš„å‚æ•°æ¥å£
        """
        super(coarse_heatmap, self).__init__()
        self.use_gpu = config.use_gpu
        self.landmarkNum = config.landmarkNum
        self.depth, self.height, self.width = config.image_scale
        self.sigma = getattr(config, 'sigma', 2.0)  # sigmaï¼Œé»˜è®¤ç”¨ 2 (ä¸ä½ æ—§ä»£ç çš„ dev=2 ä¸€è‡´)

    def generate_target_heatmap(self, labels_pixel, batch_size, device):
        """
        [å†…éƒ¨å‡½æ•°] ç°åœºç”Ÿæˆé«˜æ–¯çƒ­å›¾ï¼Œæ›¿ä»£æ—§ä»£ç çš„ self.HeatMap_groundTruth è£å‰ªé€»è¾‘
        ä¿®å¤äº†æ—§ä»£ç ä¸­ X/Y è½´æ˜ å°„é”™è¯¯çš„ Bugã€‚
        """
        # 1. åˆ›å»ºåæ ‡ç½‘æ ¼ (D, H, W)
        # indexing='ij' æ„å‘³ç€ç»´åº¦é¡ºåºæ˜¯ (Axis 0, Axis 1, Axis 2) -> (D, H, W)
        z = torch.arange(self.depth, device=device).float()
        h = torch.arange(self.height, device=device).float()
        w = torch.arange(self.width, device=device).float()
        
        grid_z, grid_h, grid_w = torch.meshgrid(z, h, w, indexing='ij')
        
        targets = []
        
        for b in range(batch_size):
            batch_targets = []
            for n in range(self.landmarkNum):
                # labels_pixel æ˜¯ [x, y, z] -> [Width, Height, Depth]
                real_x = labels_pixel[b, n, 0] # Width
                real_y = labels_pixel[b, n, 1] # Height
                real_z = labels_pixel[b, n, 2] # Depth
                
                # [Mask Check] ç¼ºå¤±å€¼å¤„ç†ï¼šç”Ÿæˆå…¨é»‘å›¾ (ä¸æ—§ä»£ç é€»è¾‘ä¸€è‡´)
                if labels_pixel[b, n, 0] < 0: 
                    batch_targets.append(torch.zeros_like(grid_z))
                    continue
                
                # [ç”Ÿæˆé«˜æ–¯]
                # å…³é”®ä¿®å¤ï¼šæ­£ç¡®å¯¹åº”åæ ‡è½´
                # grid_w å¯¹åº” Width (x), grid_h å¯¹åº” Height (y), grid_z å¯¹åº” Depth (z)
                dist_sq = (grid_w - real_x)**2 + (grid_h - real_y)**2 + (grid_z - real_z)**2
                
                # ç”Ÿæˆæœªå½’ä¸€åŒ–çš„é«˜æ–¯
                heatmap = torch.exp(-dist_sq / (2 * self.sigma**2))
                
                # [å½’ä¸€åŒ–] 
                # æ—§ä»£ç ä¸­: coarse_heatmap_gt / sum
                # CoarseNet è¾“å‡ºçš„æ˜¯æ¦‚ç‡åˆ†å¸ƒï¼ˆSum=1ï¼‰ï¼Œæ‰€ä»¥ GT ä¹Ÿå¿…é¡» Sum=1
                heatmap_sum = heatmap.sum()
                if heatmap_sum > 0:
                    heatmap = heatmap / heatmap_sum
                
                batch_targets.append(heatmap)
            
            # Stack landmarks: (N, D, H, W)
            targets.append(torch.stack(batch_targets))
            
        # Stack batch: (B, N, D, H, W)
        return torch.stack(targets)

    def forward(self, predicted_heatmap, local_coordinate, labels, phase):
        """
        å‰å‘ä¼ æ’­ï¼šä¿æŒæ¥å£å®Œå…¨ä¸å˜
        predicted_heatmap: list of tensors [(B, D, H, W), ...]
        local_coordinate: æš‚æ—¶æ²¡ç”¨åˆ° (ä¿æŒæ¥å£å…¼å®¹)
        labels: (B, N, 3) å½’ä¸€åŒ–åæ ‡
        phase: æš‚æ—¶æ²¡ç”¨åˆ°
        """
        batch_size = labels.shape[0]
        
        # 1. [é€‚é…æ—§è¾“å…¥] å°† list è½¬ä¸º tensor
        # CoarseNet è¾“å‡ºæ˜¯ listï¼Œè¿™é‡Œ stack èµ·æ¥æ–¹ä¾¿å¹¶è¡Œè®¡ç®—
        # Shape: (B, N, D, H, W)
        pred_tensor = torch.stack(predicted_heatmap, dim=1)
        
        # 2. [åæ ‡è½¬æ¢] å½’ä¸€åŒ– -> åƒç´ åæ ‡
        # labels æ˜¯ [x, y, z]ï¼Œå¯¹åº” [Width, Height, Depth]
        scale = torch.tensor([self.width-1, self.height-1, self.depth-1], device=labels.device)
        labels_pixel = labels * scale

        # 3. [ç”ŸæˆçœŸå€¼]
        with torch.no_grad(): # GT ç”Ÿæˆä¸éœ€è¦æ¢¯åº¦
            target_heatmap = self.generate_target_heatmap(labels_pixel, batch_size, labels.device)
        
        # 4. [è®¡ç®— Loss]
        # Mask: æ‰¾å‡ºæœ‰æ•ˆç‚¹ (x >= 0)
        # shape: (B, N, 1, 1, 1) ä»¥ä¾¿å¹¿æ’­
        mask = (labels[:, :, 0] >= 0).view(batch_size, self.landmarkNum, 1, 1, 1).float()
        
        # [æ ¸å¿ƒæ”¹åŠ¨] ä½¿ç”¨ MSE Loss (L2) æ›¿ä»£ L1 Loss
        # åŸå› ï¼šå¯¹äºé«˜æ–¯çƒ­å›¾å›å½’ï¼ŒMSE é€šå¸¸æ¯” L1 æ”¶æ•›æ›´ç¨³ã€æ›´å¿«ï¼Œä¸”å¯¹å³°å€¼æ›´æ•æ„Ÿã€‚
        # åŒæ—¶ä¿ç•™äº† Mask æœºåˆ¶
        # loss = (pred_tensor - target_heatmap) ** 2 
        loss = abs(pred_tensor - target_heatmap)    # æš‚æ—¶å…ˆä½¿ç”¨L1 Loss
        
        # åªå¯¹æœ‰æ•ˆç‚¹æ±‚å’Œ
        total_loss = (loss * mask).sum()
        
        # å½’ä¸€åŒ– Lossï¼šé™¤ä»¥æœ‰æ•ˆç‚¹çš„æ•°é‡ (é˜²æ­¢ batch size å˜åŒ–å¯¼è‡´ loss æ³¢åŠ¨)
        # æ³¨æ„ï¼šè¿™é‡Œåˆ†æ¯åŠ äº† epsilon é˜²æ­¢é™¤é›¶
        valid_points_count = mask.sum() + 1e-8
        
        return total_loss / valid_points_count

# TODOï¼š ç”¨åˆ°äº†è¿™ä¸ª
class fine_heatmap(nn.Module):
    def __init__(self, config):
        # use_gpu, batchSize, landmarkNum, cropSize
        super(fine_heatmap, self).__init__()
        self.use_gpu = config.use_gpu
        self.batchSize = config.batchSize
        self.landmarkNum = config.landmarkNum
        
        self.Long, self.higth, self.width = config.crop_size # (64, 64, 64) or similar
        self.binaryLoss = nn.BCEWithLogitsLoss(reduction='none') # æ”¹ä¸º none

        self.HeatMap_groundTruth = torch.zeros(self.Long, self.higth, self.width).cuda(self.use_gpu)

        rr = 11
        dev = 2
        referPoint = (self.Long//2, self.higth//2, self.width//2)
        
        # é¢„è®¡ç®—é«˜æ–¯åˆ†å¸ƒ (Center-based)
        for k in range(referPoint[0] - rr, referPoint[0] + rr + 1):
            for i in range(referPoint[1] - rr, referPoint[1] + rr + 1):
                for j in range(referPoint[2] - rr, referPoint[2] + rr + 1):
                    temdis = MyUtils.Mydist3D(referPoint, (k, i, j))
                    if temdis <= rr:
                        self.HeatMap_groundTruth[k][i][j] = math.exp(-1 * temdis**2 / (2 * dev**2))

    def forward(self, predicted_heatmap, labels=None):
        # æ³¨æ„ï¼šåŸä»£ç  forward åªæ¥å— predicted_heatmap
        # æˆ‘ä»¬ä¿®æ”¹äº† TrainNet è°ƒç”¨ï¼Œä¼ å…¥ labels ä»¥ä¾¿åš Mask
        
        # å¦‚æœ TrainNet æ²¡ä¼  labelsï¼Œå°±å‡è®¾å…¨éƒ¨æœ‰æ•ˆ (å…¼å®¹æ—§ä»£ç )
        if labels is None:
            mask = torch.ones(predicted_heatmap.shape[0], self.landmarkNum).cuda(self.use_gpu)
        else:
            # labels: (B, N, 3) -> mask: (B, N)
            mask = (labels[:, :, 0] >= 0).float()

        loss = 0
        total_valid = 0

        # predicted_heatmap: (B, N, D, H, W)
        batch_size = predicted_heatmap.shape[0]

        for b in range(batch_size):
            for i in range(self.landmarkNum):
                # å¦‚æœè¯¥ç‚¹ç¼ºå¤±ï¼Œè·³è¿‡
                if mask[b, i] == 0:
                    continue
                
                # è®¡ç®— BCE Loss
                # è¿™é‡Œçš„ GT æ˜¯ä»¥ä¸­å¿ƒä¸ºå³°å€¼çš„é«˜æ–¯åˆ†å¸ƒ (å› ä¸º Fine Stage æ˜¯ Offset å›å½’ï¼Œç›®æ ‡å°±æ˜¯ä¸­å¿ƒ)
                # æˆ–è€…æ˜¯ Heatmap Regression on cropped patch?
                # SA-LSTM çš„ fine stage æ˜¯å›å½’ç›¸å¯¹äº patch ä¸­å¿ƒçš„ heatmap
                
                bce = self.binaryLoss(predicted_heatmap[b, i], self.HeatMap_groundTruth)
                loss += bce.sum()
                total_valid += 1
        
        if total_valid > 0:
            return loss / total_valid # å¹³å‡ Loss
        else:
            return torch.tensor(0.0).cuda(self.use_gpu)

class fine_offset(nn.Module):
    def __init__(self, use_gpu, batchSize, landmarkNum):
        super(fine_offset, self).__init__()
        self.use_gpu = use_gpu
        self.batchSize = batchSize
        self.landmarkNum = landmarkNum
        self.l1Loss = nn.L1Loss(size_average=False)

    def forward(self, predicted_coordinate, local_coordinate, labels, ROIs_b, base_coordinate, phase):
        loss = 0
        # print('predict ', predicted_point_offsets[0])
        # print(labels[2,:])
        # print('gt ', torch.mean(predicted_point_offsets[2]+ point_coordinate[2], dim=0))

        # for i in range(self.landmarkNum):
        #     repeat_labels = labels[i, :].unsqueeze(0).repeat(predicted_point_offsets[i].size()[0], 1)
        #     loss += self.l1Loss(predicted_point_offsets[i], repeat_labels)
            # print(point_coordinate[i])
        # return loss
        for i in range(self.landmarkNum):
            # repeat_labels = labels[0, i, :].repeat(32, 32, 32, 1)
            # print(repeat_labels.size())
            # print(labels[0, i, :])
            # print(repeat_labels[3, 3, 1, :])
            # print(repeat_labels[15, 10, 2, :])


            # repeat_ROIs = ROIs[i, :].unsqueeze(0).repeat(predicted_point_offsets[i].size()[0], 1)
            # # print("repeat_labels", repeat_labels.size())
            # # print(labels[i, :].unsqueeze(0).detach().cpu().numpy() * np.array([767, 767, 575]))
            if phase == 'val':
            #     print(labels)
            #     print((torch.abs(local_coordinate[i] - labels[0, i, :]) - torch.abs(predicted_coordinate[i] - labels[0, i, :])).view(-1, 3)[0:30, :].detach().cpu().numpy() * np.array([767, 767, 575]))
            #     print((local_coordinate[i] - labels[0, i, :]).view(-1, 3)[0:30, :].detach().cpu().numpy() * np.array([767, 767, 575]))
                print()
                print((labels[0, i, :] - local_coordinate[i]).view(-1, 3)[320:352, :].detach().cpu().numpy() * np.array([767, 767, 575]))
                print((predicted_coordinate[i] - local_coordinate[i]).view(-1, 3)[320:352, :].detach().cpu().numpy() * np.array([767, 767, 575]))
                print()
                # print((local_coordinate[i])1.view(-1, 3)[320:352, :].detach().cpu().numpy() * np.array([767, 767, 575]))
            # if phase == 'val':
            #     print((torch.abs(predicted_point_offsets[i] - repeat_labels))[0:30, :].detach().cpu().numpy() * np.array([767, 767, 575]))

            loss += torch.abs(predicted_coordinate[i] - labels[0, i, :]).sum()
            # # print(point_coordinate[i])
        return loss

class fusionLossFunc_improved(nn.Module):
    def __init__(self, use_gpu, R, imageSize, imageNum, landmarkNum):
        super(fusionLossFunc_improved, self).__init__()

        l, h, w = 72, 96, 96
        # ~ l, h, w = 144, 192, 192

        self.use_gpu = use_gpu
        self.R = R
        self.width = w
        self.higth = h
        self.Long = l

        self.binaryLoss = nn.BCEWithLogitsLoss(size_average=False)
        # ~ self.binaryLoss = nn.BCEWithLogitsLoss()

        self.huberLoss = torch.nn.L1Loss()
        # ~ self.offsetMask = torch.zeros(h, w).cuda(self.use_gpu)

        self.offsetMapx = np.ones((self.Long * 2, self.higth * 2, self.width * 2))
        self.offsetMapy = np.ones((self.Long * 2, self.higth * 2, self.width * 2))
        self.offsetMapz = np.ones((self.Long * 2, self.higth * 2, self.width * 2))

        self.HeatMap = np.zeros((self.Long * 2, self.higth * 2, self.width * 2))

        self.binary_class_groundTruth = Variable(torch.zeros(imageNum, landmarkNum, l, h, w).cuda(self.use_gpu))

        rr = R
        referPoint = (self.Long, self.higth, self.width)
        for k in range(referPoint[0] - rr, referPoint[0] + rr + 1):
            for i in range(referPoint[1] - rr, referPoint[1] + rr + 1):
                for j in range(referPoint[2] - rr, referPoint[2] + rr + 1):
                    temdis = MyUtils.Mydist3D(referPoint, (k, i, j))
                    if temdis <= rr:
                        self.HeatMap[k][i][j] = 1

        for i in range(2 * self.Long):
            self.offsetMapz[i, :, :] = self.offsetMapz[i, :, :] * i

        for i in range(2 * self.higth):
            self.offsetMapx[:, i, :] = self.offsetMapx[:, i, :] * i

        for i in range(2 * self.width):
            self.offsetMapy[:, :, i] = self.offsetMapy[:, :, i] * i

        self.offsetMapz = referPoint[0] - self.offsetMapz
        self.offsetMapx = referPoint[1] - self.offsetMapx
        self.offsetMapy = referPoint[2] - self.offsetMapy

        # print (self.HeatMap)
        # print (self.offsetMapx)
        # print (self.offsetMapy)

        self.HeatMap = Variable(torch.from_numpy(self.HeatMap)).cuda(self.use_gpu).float()

        self.offsetMapx = Variable(torch.from_numpy(self.offsetMapx)).cuda(self.use_gpu).float() / rr
        self.offsetMapy = Variable(torch.from_numpy(self.offsetMapy)).cuda(self.use_gpu).float() / rr
        self.offsetMapz = Variable(torch.from_numpy(self.offsetMapz)).cuda(self.use_gpu).float() / rr

        return

    def forward(self, featureMaps, landmarks):
        # ~ print (featureMaps.size())

        imageNum = featureMaps[0].size()[0]
        # ~ landmarkNum = int(featureMaps[0].size()[1]/3)
        landmarkNum = int(featureMaps[0].size()[1])
        # ~ landmarkNum = int(featureMaps[0].size()[1]/4)

        l, h, w = featureMaps[0].size()[2], featureMaps[0].size()[3], featureMaps[0].size()[4]
        # ~ print ("size: ", featureMaps[0].size())
        # ~ print ()
        lossOff = 0
        lossReg = 0
        loss = 0
        # print("1")
        X = np.round((landmarks[:, :, 0] * (h - 1)).numpy()).astype("int")
        Y = np.round((landmarks[:, :, 1] * (w - 1)).numpy()).astype("int")
        Z = np.round((landmarks[:, :, 2] * (l - 1)).numpy()).astype("int")

        for imageId in range(imageNum):
            for landmarkId in range(landmarkNum):
                # ~ print (Z[imageId][landmarkId], X[imageId][landmarkId], Y[imageId][landmarkId], self.HeatMap.size(), landmarkNum)
                # ~ print (l - Z[imageId][landmarkId], 2*l - Z[imageId][landmarkId], h - X[imageId][landmarkId], 2*h - X[imageId][landmarkId], w - Y[imageId][landmarkId], 2*w - Y[imageId][landmarkId])

                # ~ MyUtils.showDICOM(self.HeatMap[l - Z[imageId][landmarkId]: 2*l - Z[imageId][landmarkId], h - X[imageId][landmarkId]: 2*h - X[imageId][landmarkId], w - Y[imageId][landmarkId]: 2*w - Y[imageId][landmarkId]].detach().cpu().numpy(), X[imageId][landmarkId], Y[imageId][landmarkId], Z[imageId][landmarkId])

                self.binary_class_groundTruth[imageId, landmarkId, :, :, :] = self.HeatMap[
                                                                              l - Z[imageId][landmarkId]: 2 * l -
                                                                                                          Z[imageId][
                                                                                                              landmarkId],
                                                                              h - X[imageId][landmarkId]: 2 * h -
                                                                                                          X[imageId][
                                                                                                              landmarkId],
                                                                              w - Y[imageId][landmarkId]: 2 * w -
                                                                                                          Y[imageId][
                                                                                                              landmarkId]]
            # self.offsetMask = temMap + self.offsetMask

        indexs = self.binary_class_groundTruth > 0
        # indexs = self.offsetMask > 0
        # indexs = getMask(self.binary_class_groundTruth)
        # print("3")
        temloss = [
            [self.binaryLoss(featureMaps[0][imageId][landmarkId], self.binary_class_groundTruth[imageId][landmarkId])]
            # ~ , \

            # ~ self.huberLoss(featureMaps[0][imageId][landmarkId + landmarkNum*1][indexs[imageId][landmarkId]], \
            # ~ self.offsetMapx[l - Z[imageId][landmarkId]: 2*l - Z[imageId][landmarkId], h - X[imageId][landmarkId]: 2*h - X[imageId][landmarkId], w - Y[imageId][landmarkId]: 2*w - Y[imageId][landmarkId]][indexs[imageId][landmarkId]]) , \

            # ~ self.huberLoss(featureMaps[0][imageId][landmarkId + landmarkNum*2][indexs[imageId][landmarkId]], \
            # ~ self.offsetMapy[l - Z[imageId][landmarkId]: 2*l - Z[imageId][landmarkId], h - X[imageId][landmarkId]: 2*h - X[imageId][landmarkId], w - Y[imageId][landmarkId]: 2*w - Y[imageId][landmarkId]][indexs[imageId][landmarkId]]), \

            # ~ self.huberLoss(featureMaps[0][imageId][landmarkId + landmarkNum*3][indexs[imageId][landmarkId]], \
            # ~ self.offsetMapz[l - Z[imageId][landmarkId]: 2*l - Z[imageId][landmarkId], h - X[imageId][landmarkId]: 2*h - X[imageId][landmarkId], w - Y[imageId][landmarkId]: 2*w - Y[imageId][landmarkId]][indexs[imageId][landmarkId]])]

            for imageId in range(imageNum)
            for landmarkId in range(landmarkNum)]
        loss1 = (sum([sum(temloss[ind]) for ind in range(imageNum * landmarkNum)])) / (imageNum * landmarkNum)
        # print("4")

        return loss1


class fusionLossFunc_improved_2(nn.Module):
    def __init__(self, use_gpu, R, imageSize, imageNum, landmarkNum):
        super(fusionLossFunc_improved_2, self).__init__()

        # ~ l, h, w = 96, 96, 96
        # ~ l, h, w = 48, 48, 48
        l, h, w = 64, 64, 64

        self.use_gpu = use_gpu
        self.R = R
        self.width = w
        self.higth = h
        self.Long = l

        self.binaryLoss = nn.BCEWithLogitsLoss(size_average=False)
        # ~ self.binaryLoss = nn.BCEWithLogitsLoss()

        self.huberLoss = torch.nn.L1Loss()
        # ~ self.offsetMask = torch.zeros(h, w).cuda(self.use_gpu)

        self.offsetMapx = np.ones((self.Long * 2, self.higth * 2, self.width * 2))
        self.offsetMapy = np.ones((self.Long * 2, self.higth * 2, self.width * 2))
        self.offsetMapz = np.ones((self.Long * 2, self.higth * 2, self.width * 2))

        self.HeatMap = np.zeros((self.Long * 2, self.higth * 2, self.width * 2))

        rr = R
        referPoint = (self.Long, self.higth, self.width)
        for k in range(referPoint[0] - rr, referPoint[0] + rr + 1):
            for i in range(referPoint[1] - rr, referPoint[1] + rr + 1):
                for j in range(referPoint[2] - rr, referPoint[2] + rr + 1):
                    temdis = MyUtils.Mydist3D(referPoint, (k, i, j))
                    if temdis <= rr:
                        self.HeatMap[k][i][j] = 1

        for i in range(2 * self.Long):
            self.offsetMapz[i, :, :] = self.offsetMapz[i, :, :] * i

        for i in range(2 * self.higth):
            self.offsetMapx[:, i, :] = self.offsetMapx[:, i, :] * i

        for i in range(2 * self.width):
            self.offsetMapy[:, :, i] = self.offsetMapy[:, :, i] * i

        self.offsetMapz = referPoint[0] - self.offsetMapz
        self.offsetMapx = referPoint[1] - self.offsetMapx
        self.offsetMapy = referPoint[2] - self.offsetMapy

        # print (self.HeatMap)
        # print (self.offsetMapx)
        # print (self.offsetMapy)

        # ~ self.HeatMap = Variable(torch.from_numpy(self.HeatMap)).cuda(self.use_gpu).float()

        self.binary_class_groundTruth = torch.from_numpy(
            self.HeatMap[l - l // 2: 2 * l - l // 2, h - h // 2: 2 * h - h // 2, w - w // 2: 2 * w - w // 2]).cuda(
            self.use_gpu).float()

        # ~ self.offsetMapx = Variable(torch.from_numpy(self.offsetMapx)).cuda(self.use_gpu).float() / rr
        # ~ self.offsetMapy = Variable(torch.from_numpy(self.offsetMapy)).cuda(self.use_gpu).float() / rr
        # ~ self.offsetMapz = Variable(torch.from_numpy(self.offsetMapz)).cuda(self.use_gpu).float() / rr

        return

    def forward(self, featureMaps, landmarks):

        imageNum, landmarkNum, l, h, w = featureMaps.size()
        # ~ print ("size: ", featureMaps[0].size())
        # ~ print ()
        lossOff = 0
        lossReg = 0
        loss = 0

        indexs = self.binary_class_groundTruth > 0
        # print("3")
        temloss = [[self.binaryLoss(featureMaps[imageId][landmarkId], self.binary_class_groundTruth)]
                   # ~ , \

                   # ~ self.huberLoss(featureMaps[0][imageId][landmarkId + landmarkNum*1][indexs[imageId][landmarkId]], \
                   # ~ self.offsetMapx[l - Z[imageId][landmarkId]: 2*l - Z[imageId][landmarkId], h - X[imageId][landmarkId]: 2*h - X[imageId][landmarkId], w - Y[imageId][landmarkId]: 2*w - Y[imageId][landmarkId]][indexs[imageId][landmarkId]]) , \

                   # ~ self.huberLoss(featureMaps[0][imageId][landmarkId + landmarkNum*2][indexs[imageId][landmarkId]], \
                   # ~ self.offsetMapy[l - Z[imageId][landmarkId]: 2*l - Z[imageId][landmarkId], h - X[imageId][landmarkId]: 2*h - X[imageId][landmarkId], w - Y[imageId][landmarkId]: 2*w - Y[imageId][landmarkId]][indexs[imageId][landmarkId]]), \

                   # ~ self.huberLoss(featureMaps[0][imageId][landmarkId + landmarkNum*3][indexs[imageId][landmarkId]], \
                   # ~ self.offsetMapz[l - Z[imageId][landmarkId]: 2*l - Z[imageId][landmarkId], h - X[imageId][landmarkId]: 2*h - X[imageId][landmarkId], w - Y[imageId][landmarkId]: 2*w - Y[imageId][landmarkId]][indexs[imageId][landmarkId]])]

                   for imageId in range(imageNum)
                   for landmarkId in range(landmarkNum)]
        loss2 = (sum([sum(temloss[ind]) for ind in range(imageNum * landmarkNum)])) / (imageNum * landmarkNum)
        # print("4")

        return loss2


class fusionLossFunc_improved_2_b(nn.Module):
    def __init__(self, use_gpu, R, imageSize, imageNum, landmarkNum):
        super(fusionLossFunc_improved_2_b, self).__init__()

        # ~ l, h, w = 96, 96, 96
        # ~ l, h, w = 48, 48, 48
        l, h, w = 64, 64, 64

        self.use_gpu = use_gpu
        self.R = R
        self.width = w
        self.higth = h
        self.Long = l

        self.binaryLoss = nn.BCEWithLogitsLoss(size_average=False)
        # ~ self.binaryLoss = nn.BCEWithLogitsLoss()

        self.huberLoss = torch.nn.L1Loss(size_average=False)
        # ~ self.offsetMask = torch.zeros(h, w).cuda(self.use_gpu)

        self.offsetMapx = np.ones((self.Long * 2, self.higth * 2, self.width * 2))
        self.offsetMapy = np.ones((self.Long * 2, self.higth * 2, self.width * 2))
        self.offsetMapz = np.ones((self.Long * 2, self.higth * 2, self.width * 2))

        self.HeatMap = np.zeros((self.Long * 2, self.higth * 2, self.width * 2))

        rr = R
        referPoint = (self.Long, self.higth, self.width)
        for k in range(referPoint[0] - rr, referPoint[0] + rr + 1):
            for i in range(referPoint[1] - rr, referPoint[1] + rr + 1):
                for j in range(referPoint[2] - rr, referPoint[2] + rr + 1):
                    temdis = MyUtils.Mydist3D(referPoint, (k, i, j))
                    if temdis <= rr:
                        self.HeatMap[k][i][j] = 1

        for i in range(2 * self.Long):
            self.offsetMapz[i, :, :] = self.offsetMapz[i, :, :] * i

        for i in range(2 * self.higth):
            self.offsetMapx[:, i, :] = self.offsetMapx[:, i, :] * i

        for i in range(2 * self.width):
            self.offsetMapy[:, :, i] = self.offsetMapy[:, :, i] * i

        self.offsetMapz = referPoint[0] - self.offsetMapz
        self.offsetMapx = referPoint[1] - self.offsetMapx
        self.offsetMapy = referPoint[2] - self.offsetMapy

        # print (self.HeatMap)
        # print (self.offsetMapx)
        # print (self.offsetMapy)

        # ~ self.HeatMap = Variable(torch.from_numpy(self.HeatMap)).cuda(self.use_gpu).float()

        self.binary_class_groundTruth = torch.from_numpy(
            self.HeatMap[l - l // 2: 2 * l - l // 2, h - h // 2: 2 * h - h // 2, w - w // 2: 2 * w - w // 2]).cuda(
            self.use_gpu).float()

        # ~ self.offsetMapx = torch.from_numpy(self.offsetMapx[l - l//2: 2*l - l//2, h - h//2: 2*h - h//2, w - w//2: 2*w - w//2]).cuda(self.use_gpu).float() / rr
        # ~ self.offsetMapy = torch.from_numpy(self.offsetMapy[l - l//2: 2*l - l//2, h - h//2: 2*h - h//2, w - w//2: 2*w - w//2]).cuda(self.use_gpu).float() / rr
        # ~ self.offsetMapz = torch.from_numpy(self.offsetMapz[l - l//2: 2*l - l//2, h - h//2: 2*h - h//2, w - w//2: 2*w - w//2]).cuda(self.use_gpu).float() / rr

        self.offsetMapx = torch.from_numpy(
            self.offsetMapx[l - l // 2: 2 * l - l // 2, h - h // 2: 2 * h - h // 2, w - w // 2: 2 * w - w // 2]).cuda(
            self.use_gpu).float() / 63
        self.offsetMapy = torch.from_numpy(
            self.offsetMapy[l - l // 2: 2 * l - l // 2, h - h // 2: 2 * h - h // 2, w - w // 2: 2 * w - w // 2]).cuda(
            self.use_gpu).float() / 63
        self.offsetMapz = torch.from_numpy(
            self.offsetMapz[l - l // 2: 2 * l - l // 2, h - h // 2: 2 * h - h // 2, w - w // 2: 2 * w - w // 2]).cuda(
            self.use_gpu).float() / 63

    def forward(self, featureMaps, landmarks):

        imageNum, landmarkNum, l, h, w = featureMaps.size()
        landmarkNum = int(landmarkNum / 4)
        # ~ print ("size: ", featureMaps[0].size())
        # ~ print ()
        lossOff = 0
        lossReg = 0
        loss = 0

        indexs = self.binary_class_groundTruth > 0
        # print("3")
        temloss = [[self.binaryLoss(featureMaps[imageId][landmarkId * 4], self.binary_class_groundTruth), \
 \
                    self.huberLoss(featureMaps[imageId][landmarkId * 4 + 1], \
                                   self.offsetMapx), \
 \
                    self.huberLoss(featureMaps[imageId][landmarkId * 4 + 2], \
                                   self.offsetMapy), \
 \
                    self.huberLoss(featureMaps[imageId][landmarkId * 4 + 3], \
                                   self.offsetMapz)]

                   for imageId in range(imageNum)
                   for landmarkId in range(landmarkNum)]
        loss2 = (sum([sum(temloss[ind]) for ind in range(imageNum * landmarkNum)])) / (imageNum * landmarkNum)
        # print("4")

        return loss2
