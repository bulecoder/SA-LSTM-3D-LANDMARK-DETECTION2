from __future__ import print_function, division
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable
import numpy as np
import torchvision
from torchvision import models, transforms, utils
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
import time
import os
from skimage import io, transform
import math
from copy import deepcopy
import pandas as pd
import math
import copy
import time
import PIL
# import angle
from PIL import Image, ImageDraw, ImageFont
from scipy.ndimage import zoom
import MyUtils
import torch.nn.functional as F
import zipfile
import cv2

class ZipDataset(Dataset):
    def __init__(self, root_path, cache_into_memory=False):
        if cache_into_memory:
            f = open(root_path, 'rb')
            self.zip_content = f.read()
            f.close()
            self.zip_file = zipfile.ZipFile(io.BytesIO(self.zip_content), 'r')
        else:
            self.zip_file = zipfile.ZipFile(root_path, 'r')
        self.name_list = list(filter(lambda x: x[-4:] == '.jpg', self.zip_file.namelist()))
        self.to_tensor = ToTensor()

    def __getitem__(self, key):
        buf = self.zip_file.read(name=self.name_list[key])
        img = self.to_tensor(cv2.imdecode(np.fromstring(buf, dtype=np.uint8), cv2.IMREAD_COLOR))
        return img

    def __len__(self):
        return len(self.name_list)


'''
if __name__ == '__main__':
    dataset = ZipDataset('COCO.zip', cache_into_memory=False)
    dataloader = DataLoader(dataset, batch_size=2, num_workers=2)
    for batch_idx, sample in enumerate(dataloader):
        print(batch_idx, sample.size())
'''


class Rescale(object):
    """
    å°† CSV ä¸­çš„ç»å¯¹åæ ‡ (0~512) å½’ä¸€åŒ–åˆ° (0~1) ä¹‹é—´ã€‚
    æ³¨æ„ï¼šinput_size å¿…é¡»æ˜¯ Fine Stage çš„å°ºå¯¸ (512, 512, 512)ã€‚
    """
    def __init__(self, input_size):
        self.input_size = input_size

    def __call__(self, sample):
        DICOM, DICOM_origin, landmarks, imageName = sample['DICOM'], sample['DICOM_origin'], sample['landmarks'], sample['imageName']
        
        # self.input_size åº”è¯¥æ˜¯ (512, 512, 512)
        d, h, w = self.input_size
        
        # å½’ä¸€åŒ–åæ ‡ï¼šx' = x / width
        # æ³¨æ„ï¼šä¸ºäº†ä¿æŒ -1 (ç¼ºå¤±å€¼) ä»ç„¶æ˜¯è´Ÿæ•°ï¼Œç›´æ¥é™¤ä»¥å°ºå¯¸å³å¯
        # å‡è®¾ landmarks é¡ºåºæ˜¯ x, y, z (å¯¹åº” W, H, D)
        # æ ¹æ®æˆ‘ä»¬ prepare_data çš„é€»è¾‘ï¼Œæˆ‘ä»¬å­˜çš„æ˜¯ voxel åæ ‡ (d0, d1, d2) ä¹Ÿå°±æ˜¯ (D, H, W) æˆ–è€…æ˜¯ (x, y, z)?
        # MONAI è¿™é‡Œçš„åæ ‡ç³»é€šå¸¸æ˜¯ RASã€‚æˆ‘ä»¬ä¹‹å‰çš„è„šæœ¬å­˜çš„æ˜¯ numpy index (D, H, W)ã€‚
        # æ‰€ä»¥æˆ‘ä»¬éœ€è¦æŒ‰ (D, H, W) çš„å°ºå¯¸æ¥å½’ä¸€åŒ–ã€‚
        # æ—¢ç„¶æˆ‘ä»¬è®¾å®šæ˜¯ç«‹æ–¹ä½“ (512, 512, 512)ï¼Œé‚£ä¹ˆé™¤ä»¥å“ªä¸ªéƒ½ä¸€æ ·ã€‚
        
        landmarks = landmarks / [d, h, w] 
        
        return {'DICOM': DICOM, 'DICOM_origin': DICOM_origin, 'landmarks': landmarks, 'imageName': imageName}

class ToTensor(object):
    """Convert ndarrays in sample to Tensors."""

    def __call__(self, sample):
        DICOM, DICOM_origin, landmarks, imageName = sample['DICOM'], sample['DICOM_origin'], sample['landmarks'], sample['imageName']

        # ä¸å†åš Z-Score æ ‡å‡†åŒ–   åç»­åšäº† 0-1å½’ä¸€åŒ–
        # # --- 1. æ ‡å‡†åŒ– (Z-Score) ---
        # std = np.std(DICOM)
        # DICOM = (DICOM - np.mean(DICOM)) / std if std > 0 else DICOM - np.mean(DICOM)
            
        # std_origin = np.std(DICOM_origin)
        # DICOM_origin = (DICOM_origin - np.mean(DICOM_origin)) / std_origin if std_origin > 0 else DICOM_origin - np.mean(DICOM_origin)

        # è·å–å°ºå¯¸
        shape = np.array(DICOM_origin.shape) # (512, 512, 512)
        
        # --- 2. å‡†å¤‡åˆ‡å›¾åæ ‡ ---
        crop_landmarks_pixel = landmarks.copy() 
        
        # [A] å¤„ç†ç¼ºå¤±å€¼ (-1) -> è®¾ä¸ºä¸­å¿ƒ
        missing_mask = crop_landmarks_pixel[:, 0] < 0
        center = shape / 2.0
        crop_landmarks_pixel[missing_mask] = center
        
        # [B] å®‰å…¨é’³ä½ (Clamp)
        CROP_SIZE = 96
        SAFE_MARGIN = CROP_SIZE // 2
        
        min_limit = SAFE_MARGIN
        max_limit = shape - SAFE_MARGIN
        
        # æ‰§è¡Œé’³ä½
        crop_landmarks_pixel = np.clip(crop_landmarks_pixel, min_limit, max_limit)

        # --- 3. æ‰§è¡Œåˆ‡ Patch ---
        DICOM_origin_tensor = torch.from_numpy(DICOM_origin).float().unsqueeze(0).unsqueeze(0)
        
        # ä¼ å…¥åƒç´ åæ ‡ (float32)
        crop_coords_input = crop_landmarks_pixel.reshape(1, -1, 3).astype(np.float32)
        
        # è°ƒç”¨ä¿®å¤åçš„ MyUtils
        crop_list = MyUtils.getcropedInputs(crop_coords_input, DICOM_origin_tensor, CROP_SIZE, -1)
        # crop_list = [item.unsqueeze(0) for item in crop_list]

        # --- 4. è¿”å› ---
        # å½’ä¸€åŒ–åæ ‡ (ä½¿ç”¨åŸå§‹åæ ‡ï¼Œä¿ç•™ -1 ä¿¡æ¯ä¾› Loss ä½¿ç”¨)
        landmarks_normalized = landmarks / shape

        # # ğŸ”¥ [DEBUG] æ‰“å°æºå¤´å½¢çŠ¶
        # if len(crop_list) > 0:
        #     print(f"\n[DEBUG 1 - Source] crop_list[0] shape in MyDataLoader: {crop_list[0].shape}")

        return {
            'DICOM': torch.from_numpy(DICOM).float().unsqueeze(0), 
            'DICOM_origin': crop_list,
            'DICOM_origin_vis': DICOM, 
            'landmarks': torch.from_numpy(landmarks_normalized).float(), 
            'size': shape, 
            'imageName': imageName
        }


class LandmarksDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None, landmarksNum=7):
        print(f"ğŸ“– Loading Dataset from: {csv_file}")
        self.landmarks_frame = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        self.landmarkNum = landmarksNum
        print(f"   Found {len(self.landmarks_frame)} samples.")

    def __len__(self):
        return len(self.landmarks_frame)

    # HUé˜ˆå€¼æˆªæ–­å½’ä¸€åŒ–
    def _clip_normalize_cbct(self, image):
        """
        ä¸“ä¸º CBCT è®¾è®¡çš„å½’ä¸€åŒ–å‡½æ•°  ç­–ç•¥:Windowing [-1000, 1000] -> Normalize [0, 1]
        """
        image = image.astype(np.float32)    # 1. è½¬æ¢ä¸º float32 (èŠ‚çœæ˜¾å­˜ï¼Œä¸” PyTorch éœ€è¦)
        MIN_HU = -1000.0
        MAX_HU = 1000.0
        image = np.clip(image, MIN_HU, MAX_HU)   # 2. ç‰©ç†æˆªæ–­ (Windowing)   å»æ‰é‡‘å±ä¼ªå½±æé«˜äº®çš„å½±å“ï¼ŒåŒæ—¶ä¿ç•™ç©ºæ°”å’Œéª¨éª¼çš„å¯¹æ¯”åº¦
        image = (image - MIN_HU) / (MAX_HU - MIN_HU)    # 3. å½’ä¸€åŒ–åˆ° 0~1
        return image

    # æœ´ç´ å½’ä¸€åŒ–
    def _minmax_normalize_cbct(self, image):
        """
        ç­–ç•¥ B: æœ´ç´ æ–¹æ³•ã€‚å®Œå…¨ä¾èµ–å½“å‰å›¾ç‰‡çš„æœ€å¤§æœ€å°å€¼ã€‚
        """
        image = image.astype(np.float32)
        min_val = image.min()
        max_val = image.max()
        if max_val - min_val > 1e-5:
            image = (image - min_val) / (max_val - min_val) # é˜²æ­¢é™¤ä»¥ 0 (è™½ç„¶æ¦‚ç‡å¾ˆå°ï¼Œä½†å¿…é¡»æœ‰)
        else:
            image = image - min_val # æˆ–è€…å…¨å˜ 0
        return image

    def __getitem__(self, idx):
        filename = self.landmarks_frame.iloc[idx, 0]
        
        # ğŸ” æ‰“å°è¿›åº¦ (æ¯ 10 ä¸ªæ ·æœ¬æ‰“å°ä¸€æ¬¡ï¼Œé˜²æ­¢åˆ·å±)
        if idx % 10 == 0:
            print(f"   Loading sample [{idx}/{len(self)}]: {filename}")
        
        img_name_coarse = os.path.join(self.root_dir, "96_" + filename)
        img_name_fine = os.path.join(self.root_dir, filename)
        
        try:
            image_coarse = np.load(img_name_coarse)  
            image_fine = np.load(img_name_fine)  
            # å½’ä¸€åŒ–
            image_coarse = self._minmax_normalize_cbct(image_coarse)
            image_fine = self._minmax_normalize_cbct(image_fine)
        except Exception as e:
            print(f"âŒ Error loading {filename}: {e}")
            raise e

        landmarks = self.landmarks_frame.iloc[idx, 1:self.landmarkNum * 3 + 1].values.astype('float')
        landmarks = landmarks.reshape(-1, 3)

        sample = {
            'DICOM': image_coarse, 
            'DICOM_origin': image_fine, 
            'landmarks': landmarks, 
            'imageName': filename
        }

        if self.transform:
            sample = self.transform(sample)

        return sample
